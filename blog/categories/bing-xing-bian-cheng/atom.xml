<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 并行编程 | Yebangyu's Blog]]></title>
  <link href="http://www.yebangyu.org/blog/categories/bing-xing-bian-cheng/atom.xml" rel="self"/>
  <link href="http://www.yebangyu.org/"/>
  <updated>2016-01-10T12:09:43+08:00</updated>
  <id>http://www.yebangyu.org/</id>
  <author>
    <name><![CDATA[Yebangyu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Memory Consistency和Cache Coherence]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/09/memoryconsistencyandcachecoherence/"/>
    <updated>2016-01-09T22:52:52+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/09/memoryconsistencyandcachecoherence</id>
    <content type="html"><![CDATA[<h2 id="memory-consistency">Memory Consistency</h2>

<p><strong>Memory Consistency</strong>(<strong>MC</strong>)，有时候又叫做<strong>Memory Consistency Model</strong>或者<strong>Memory Model</strong>。为了理解为什么需要引入这种东西，我们首先看以下程序：</p>

<!--more-->

<pre><code>初始：x=0 y=0

Thread1：

S1：x=1

L1：r1=y

Thread2：

S2：y=2

L2：r2=x
</code></pre>

<p>其中，<strong>S1、S2、L1、L2</strong>是语句代号（<strong>BTW</strong>，<strong>S</strong>表示<strong>Store</strong>，<strong>L</strong>表示<strong>Load</strong>）；<strong>r1</strong>和<strong>r2</strong>是两个寄存器。<strong>x</strong>和<strong>y</strong>是两个不同的内存变量。</p>

<p>两个线程执行完之后，<strong>r1</strong>和<strong>r2</strong>可能是什么值？两个线程执行完之后，<strong>r1</strong>和<strong>r2</strong>可能是什么值？</p>

<p>注意到线程是并发、交替执行的，下面是可能的执行顺序和相应结果：</p>

<p><strong>S1 L1 S2 L2</strong> 那么<strong>r1=0 r2=2</strong></p>

<p><strong>S1 S2 L1 L2</strong> 那么<strong>r1=2 r2=1</strong></p>

<p><strong>S2 L2 S1 L1</strong> 那么<strong>r1=2 r2=0</strong></p>

<p>这些都是意料之内、情理之中的。但是在<strong>x86</strong>体系结构下，很可能得到<strong>r1=0 r2=0</strong>这样的结果。是不是大吃一惊？</p>

<p>如果没有<strong>Memory Consistency</strong>，那么程序员对于自己编写的多线程程序会输出什么将一无所知：天知道会输出什么。</p>

<p>因此，<strong>Memory Consistency</strong>就是程序员（编程语言）、编译器、CPU间的一种协议。这个协议保证了程序访问内存时可能得到什么值，会得到什么值。</p>

<h2 id="sequential-consistency">Sequential Consistency</h2>

<p>在<strong>Sequential Consistency</strong>这种<strong>Memory Model</strong>下，刚才讨论的那个程序不可能输出<strong>r1=0 r2=0</strong>这种结果。怎么说？这就牵涉到一个问题：什么是<strong>Sequential Consistency</strong>（<strong>SC</strong>）。</p>

<p>根据<strong>Leslie Lamport</strong>在<strong>1979</strong>年<strong>9</strong>月发表的论文《<strong>How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs</strong>》里提出的<strong>SC</strong>的定义：</p>

<p>the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.</p>

<p>根据这个定义，在<strong>SC</strong>模型下，任何<strong>execution</strong>的执行顺序（我们称为<strong>Memory Order</strong>）必须<strong>respect</strong>每个线程的<strong>Program Order</strong>。什么是<strong>Program Order</strong>？对于以上程序，在<strong>Thread1</strong>中，<strong>S1</strong>先于<strong>L1</strong>；在<strong>Thread2</strong>中，<strong>S2</strong>先于<strong>L2</strong>。这就是<strong>Program Order</strong>。</p>

<p>请时刻注意，<strong>Program Order</strong>只针对某个线程内的语句而言，不涉及到跨线程。比如<strong>Thread1</strong>中的<strong>S1</strong>和<strong>Thread2</strong>中的<strong>L2</strong>，就无所谓什么<strong>Program Order</strong>了。</p>

<p>好了，现在知道为什么在<strong>SC</strong>下，有些结果可能出现，有些不可能了。</p>

<p><strong>S1 L1 S2 L2 r1=0 r2=2</strong> 没问题，没有违背<strong>S1&lt;L1 S2&lt;L2</strong></p>

<p><strong>S1 S2 L1 L2 r1=1 r2=2</strong> 没问题，没有违背<strong>S1&lt;L1 S2&lt;L2</strong></p>

<p><strong>S2 L2 S1 L1 r1=2 r2=0</strong> 没问题，没有违背<strong>S1&lt;L1 S2&lt;L2</strong></p>

<p>而对于<strong>r1=0 r2=0</strong>，在<strong>SC</strong>下，我们找不到一个能<strong>respect Program Order</strong>的<strong>Memory Order</strong>。因为<strong>r1=0</strong>，说明<strong>L1&lt;S2</strong>，<strong>r2=0</strong>说明<strong>L2&lt;S1</strong>；而<strong>S1&lt;L1，S2&lt;L2</strong>，不难看出这里形成了一个环。</p>

<h2 id="cache-coherence">Cache Coherence</h2>

<p>还是先搬出这张图吧:</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/cpuand%20cache.png" alt="memorycache" /></p>

<p>(图片来源于<strong>Paul</strong>大叔的《<strong>Is Parallel Programming Hard</strong>》这本书第三章)</p>

<p>多个<strong>CPU cores</strong>，每个<strong>core</strong>上有自己的<strong>Cache</strong>。我们知道，<strong>Cache</strong>是部分内存的映射和缓存，或者说，副本。这就带来一个问题：副本一致性。内存只有一个，每个<strong>cpu cores</strong>却有自己的内存副本，如何保证大家看到的内容是一样的、一致的、正确的呢？这就是<strong>Cache Coherence(CC)</strong>要解决的问题。</p>

<h2 id="cache-coherence--vs-memory-consistency">Cache Coherence  VS Memory Consistency</h2>

<p>从以上分析，我们不难看出，<strong>CC</strong>和<strong>MC</strong>涉及的是两个不同层面的东西，解决的是不同的问题，不可混淆。<strong>CC</strong>解决的是副本一致性问题；<strong>MC</strong>保证的是多线程程序访问内存时可以（可能）读到什么值。</p>

<p>两者有联系吗？有。实现<strong>Memory Consistency</strong>时可能会使用到<strong>Cache Coherence</strong>。细节下次我们接着聊。</p>

<h2 id="section">附录</h2>

<p>1，在并行编程中，我们常常有一个问题，或者需求：比如说上面的那个程序，如何保证线程<strong>2</strong>读到的<strong>x</strong>是线程<strong>1</strong>更新（<strong>x=1</strong>）后的<strong>x</strong>的值呢？</p>

<p>如果不加任何同步设施，仅仅考虑上面的程序，那么答案是：无法保证。因为线程的推进速度不同，哪条指令先被执行也一无所知。这个程序重跑几次，也可能输出不同的结果出来。</p>

<p>也就是说，<strong>Memory Model</strong>保证的是，例如，当线程<strong>2</strong>看到<strong>x</strong>等于<strong>1</strong>的时候，线程<strong>1</strong>是否已经执行了<strong>L1</strong>。也就是说，<strong>Memory Model</strong>确保当一件事情发生时，有其他什么事情<strong>has happened</strong>。在<strong>SC</strong>中，当<strong>L1</strong>发生时，说明或者说暗示着，<strong>S1</strong>已经发生了。</p>

<p>2，为什么<strong>x86</strong>下可能得出<strong>r1=0 r2=0</strong>的结果？</p>

<p>因为<strong>S1</strong>是写一个内存变量而<strong>L1</strong>是读取另一个内存变量（两个变量，或者说两个内存地址），这种情况下的写读可能被<strong>CPU</strong>乱序：先执行<strong>L1</strong>，再执行<strong>S1</strong>。（为了性能，所谓的延后写）</p>

<h2 id="section-1">致谢</h2>

<p>本文发出后，微博网友@linyvxiang 指出了其中的一个笔误，非常感谢。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[诡异的程序性能问题]]></title>
    <link href="http://www.yebangyu.org/blog/2015/12/30/falsesharing/"/>
    <updated>2015-12-30T23:06:12+08:00</updated>
    <id>http://www.yebangyu.org/blog/2015/12/30/falsesharing</id>
    <content type="html"><![CDATA[<p>本文所使用的环境是<strong>Ubuntu 14.04 32bit</strong>系统，<strong>Intel I5</strong>处理器，<strong>X86</strong>体系结构</p>

<h2 id="section">提出问题</h2>

<p>如果我说下面的程序存在性能问题，您信吗？</p>

<!--more-->

<p><code>c++
#include&lt;thread&gt;
int32_t global[2]={0};
void f()
{
  for(int i = 0; i &lt; 100000000; i++) {
    ++global[0];
  }
}
void g()
{
  for(int i = 0; i &lt; 100000000; i++) {
    ++global[1];
  }
}
int main()
{
  std::thread thread1(f);
  std::thread thread2(g);
  thread1.join();
  thread2.join();
  return 0;
}
</code>
这个程序，在我的电脑上，运行时间为：</p>

<pre><code>real	0m0.822s
user	0m1.596s
sys     0m0.000s
</code></pre>

<h2 id="section-1">分析问题</h2>

<p>有人说，两个线程分别操作不同的计数器，这么完美的程序，会有性能问题？</p>

<p>答案是：有。</p>

<p>恩，原因在于大名鼎鼎的<strong>false sharing</strong>。如果您看过我以前写的<a href="http://www.yebangyu.org/blog/2015/10/18/hardwareanditshabit/">这篇</a>博客，应该还记得:现在的计算机一般由一个内存、一个<strong>CPU</strong>组成，而包含多个<strong>CPU Cores</strong>和<strong>Cache</strong>。如这幅图所示：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/cpuand%20cache.png" alt="memorycache" /></p>

<p><strong>cacheline</strong>是<strong>cache</strong>块单位，一个<strong>cacheline</strong>大小一般在<strong>32</strong>到<strong>256</strong>字节左右。<strong>cacheline</strong>是这张图中不同模块的数据交互元素。</p>

<p>在上面程序中，<strong>global</strong>是两个<strong>4</strong>字节变量构成的数组，大小为<strong>8</strong>字节，很可能被放到同一个<strong>cacheline</strong>里。当运行在<strong>CPU1 Core</strong>上的线程<strong>thread1</strong>修改了<strong>global[0]</strong>时，会让运行在<strong>CPU2 Core</strong>上对应<strong>global[0]</strong>和<strong>global[1]</strong>的<strong>cacheline</strong>失效，因此运行在<strong>CPU2 Core</strong>上的线程<strong>thread2</strong>修改<strong>global[1]</strong>时会发生<strong>cache miss</strong>，接着它访问内存，修改<strong>global[1]</strong>，这也会让<strong>CPU1 Core</strong>中的<strong>cacheline</strong>失效。很明显，这里面会有大量的<strong>cache miss</strong>和为了缓存一致性而花费的通信开销。</p>

<p>因此这种<strong>false sharing</strong>发生在多核、多线程环境中。单核或者单线程不会有<strong>false sharing</strong>问题。</p>

<p>遗憾的是，程序里存在这样的问题，并不容易通过肉眼发现。</p>

<p>幸运的是，这种问题一旦知道，就比较好解决。</p>

<h2 id="section-2">解决问题</h2>

<p>解决方法一：让这两个计数器间隔足够大，让它们不要在同一个<strong>cacheline</strong>里，不就行了么？</p>

<p>恩，定义一个<strong>global[10000]</strong>，然后线程<strong>1</strong>利用<strong>global[0]</strong>，线程<strong>2</strong>利用<strong>global[9999]</strong>，应该就可以了。</p>

<p>什么？这么愚蠢的方法都想得出来？接着往下看。</p>

<p>解决方法二：假如<strong>global</strong>不是一个数组呢？而是包含多个变量的结构体呢(这种情形也很常见)？上面的方法就不灵了吧？</p>

<p>恩，上面的方法不灵了，而且上面的方法太笨。网上有很多资料告诉您怎么定义变量让其<strong>cacheline aligned</strong>，这也是那些博客千篇一律的做法。还有没有其他方法？有。接着往下看。</p>

<p>解决方法三：重点来了。</p>

<p>我们其实可以在线程里使用局部变量！</p>

<p><code>c++
#include&lt;thread&gt;
int32_t global[2] = {0};
void f()
{
  int counter1 = 0;
  for(int i = 0; i &lt; 100000000; i++) {
    ++counter1;
  }
  global[0] = counter1;
}
void g()
{
  int counter2 =0;
  for(int i = 0; i &lt; 100000000; i++) {
    ++counter2;
  }
  global[1] = counter2;
}
int main()
{
  std::thread thread1(f);
  std::thread thread2(g);
  thread1.join();
  thread2.join();
  return 0;
}
</code>
<strong>counter1</strong>和<strong>counter2</strong>在自己的线程栈上，<strong>cacheline</strong>位于对应的<strong>CPU core</strong>里，大家相安无事。只有执行第<strong>9</strong>行和第<strong>17</strong>行时代价可能高点。</p>

<p>这个程序，在我的电脑上运行时间为：</p>

<pre><code>real	0m0.293s
user	0m0.580s
sys     0m0.000s
</code></pre>

<p>解决方法四：</p>

<p><strong>global</strong>神马变量？全局变量。<strong>counter1/counter2</strong>神马变量？局部变量。</p>

<p>有没有一种东东，既有全局的性质，又有局部的效果（线程私有）呢？</p>

<p>恩，如果您看过我以前写的<a href="http://www.yebangyu.org/blog/2015/10/31/linux-parallen-programmming-infrastructure/">这篇</a>博客，就不会对<strong>__thread</strong>感到陌生。对！提供强大<strong>scalability</strong>的利器，就是它了！</p>

<p><code>c++
#include&lt;thread&gt;
__thread int counter = 0;
void f()
{
  for(int i = 0; i &lt; 100000000; i++) {
    ++counter;
  }
}
void g()
{
  for(int i = 0; i &lt; 100000000; i++) {
    ++counter;
  }
}
int main()
{
  std::thread thread1(f);
  std::thread thread2(g);
  thread1.join();
  thread2.join();
  return 0;
}
</code></p>

<p>这个程序在我的电脑上的运行时间为：</p>

<pre><code>real	0m0.325s
user	0m0.644s
sys     0m0.000s
</code></pre>

<p>不过其他线程如何读取到每个计数线程的<strong>counter</strong>呢？不难，但是也不是那么简单，背后涉及到很多问题（其实本文最大的目的是通过<strong>false sharing</strong>，揭示<strong>partition</strong>这种并发编程里最大的设计原则）。我们下次专门聊。</p>

<h2 id="section-3">附录</h2>

<p>1，编译以上多线程程序的时候，请使用：</p>

<pre><code>g++ -pthread -std=c++11 xxx.cpp
</code></pre>

<p>如果没有指定<code>-pthread</code>，那么程序可以编译链接通过，运行时报错：</p>

<p>terminate called after throwing an instance of ‘std::system_error’</p>

<p>what():  Enable multithreading to use std::thread: Operation not permitted</p>

<p>Aborted (core dumped)</p>

<p>2，程序计时我用的是 <code>time ./a.out</code>的方式。</p>

<h2 id="section-4">致谢</h2>

<p>本文发出后，微博网友@Debin_IIE指出了一个笔误。非常感谢。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lock Free中的Hazard Pointer(中)]]></title>
    <link href="http://www.yebangyu.org/blog/2015/12/14/introduction-to-hazard-pointer/"/>
    <updated>2015-12-14T22:33:01+08:00</updated>
    <id>http://www.yebangyu.org/blog/2015/12/14/introduction-to-hazard-pointer</id>
    <content type="html"><![CDATA[<p>看过<a href="http://www.yebangyu.org/blog/2015/12/10/introduction-to-hazard-pointer/">上篇</a>的朋友，可能会认为：这不就是<strong>Smart Pointer</strong>么？于是可能写出这样的代码：</p>

<!--more-->

<p><code>c++
#include&lt;iostream&gt;
#include&lt;thread&gt;
using namespace std;
class SmartPointer
{
public:
  SmartPointer(int *p)
  {
    pointee_ = p;
    ref_counts_ = 0;
  }
  int *pointee_;
  int ref_counts_;
};
SmartPointer sp(new int(1));
void Reader()
{
  ++sp.ref_counts_;
  cout&lt;&lt;*(sp.pointee_)&lt;&lt;endl;
  --sp.ref_counts_;
}
void Writer()
{
  if (sp.ref_counts_ == 0)
    delete sp.pointee_;
}
int main()
{
  thread t1(Reader);
  thread t2(Reader);
  thread t3(Reader);
  thread t4(Writer);
  t1.join();
  t2.join();
  t3.join();
  t4.join();
  return 0;
}
</code>
然而事实上，这样做是错的。其中的<strong>race condition</strong>请读者自行分析。</p>

<p>那么，<strong>Hazard Pointer</strong>(<strong>HP</strong>)和<strong>Smart Pointer</strong>(<strong>SP</strong>)有什么区别呢？它们的共同点就是管理对应对象的生命周期，然而这两者有本质的区别，<strong>HP</strong>是线程安全的，而<strong>SP</strong>不是。</p>

<p>在<strong>HP</strong>中，每个读线程维护着自己的<strong>HP</strong> <strong>list</strong>，这个<strong>list</strong>，只由该线程写。因此，它是线程安全的。该<strong>list</strong>会（可以）被其他线程读。</p>

<p>每个写线程维护自己的<strong>retire list</strong>，该<strong>retire list</strong>只由该写线程进行读写。由于写线程可以读其他所有读线程的<strong>HP list</strong>，这样，差集（在自己的<strong>retire list</strong>，但是不在所有读线程的<strong>HP list</strong>里的指针），就是可以安全释放的指针。</p>

<p>而<strong>SP</strong>，则被多个线程读写，<strong>18、19</strong>两行也无法做成原子操作，因此，<strong>SP</strong>和<strong>HP</strong>有本质的区别，使用<strong>SP</strong>的程序往往需要搭配使用锁等设施来保证线程安全。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lock Free中的Hazard Pointer(上)]]></title>
    <link href="http://www.yebangyu.org/blog/2015/12/10/introduction-to-hazard-pointer/"/>
    <updated>2015-12-10T23:00:20+08:00</updated>
    <id>http://www.yebangyu.org/blog/2015/12/10/introduction-to-hazard-pointer</id>
    <content type="html"><![CDATA[<p>废话不多说了，直接开始讨论。</p>

<h2 id="section">险象环生</h2>

<p>首先看以下的程序，有问题吗？</p>

<!--more-->

<p><code>c++
#include&lt;iostream&gt;
#include&lt;thread&gt; //C++11中的多线程基础设施
using namespace std;
int *p = new int(2);
void reader()
{
  if (nullptr != p) { //nullptr是C++11中引入的
    cout &lt;&lt; *p &lt;&lt; endl;
  }
}
void writer()
{
  delete p;
  p = nullptr;
}
int main()
{
  thread t1(reader);
  thread t2(writer);
  t1.join();
  t2.join();
  return 0;
}
</code>
答案当然是有问题。这个程序存在如下的<strong>race</strong> <strong>condition</strong>：如果当线程<strong>reader</strong>判断完<strong>p</strong>发现它不是<strong>nullptr</strong>后，还未执行第<strong>8</strong>行就被调度出去，轮到线程<strong>writer</strong>执行，它执行完<strong>13</strong>、<strong>14</strong>行后，又继续调度线程<strong>reader</strong>，此时执行第<strong>8</strong>行导致程序崩溃。</p>

<p>这里的问题，可以不精确地表述为：多线程程序中，某线程通过一个指针访问一段内存时，如何保证指针所指向的那块内存是有效的？</p>

<h2 id="hazard-pointer">Hazard Pointer</h2>

<p>这当然有多种方法，加一把互斥锁就万事大吉了(当然，得注意锁本身的生命周期)。不过本文讨论的是<strong>lock</strong> <strong>free</strong>情况下的内存管理，这里要介绍的是<strong>2004</strong>年左右提出的<strong>Hazard</strong> <strong>Pointer</strong>方法。</p>

<p>接着看以下代码：</p>

<p>```c++
#include<thread>
#include<iostream>
#define Strong_Memory_Barrier __sync_synchronize
#define ACCESS_ONCE(x) (* (volatile typeof(x) *) &amp;(x))
using namespace std;
struct HazardPointer
{
  HazardPointer() :p_(nullptr){}
  int *p_; //Hazard Pointer封装了原始指针
};</iostream></thread></p>

<p>int *p = new int(2); //原始指针</p>

<p>HazardPointer *hp = new HazardPointer(); //只有一个线程可以写</p>

<p>class Writer
{
public:
  void retire(int *tmp) {
    retire_list = tmp;//设置要释放的指针
  }
  void gc() {
    if (retire_list == hp-&gt;p_) {
      //说明有读者正在使用它，不能释放
    } else {
      //可以安全地释放
      delete retire_list;
    }
  }
  void write() {
    int *tmp = ACCESS_ONCE(p);
    p = nullptr;
    retire(tmp);
    gc();
  }
private:
  int *retire_list;//记录待释放的指针
};
class Reader
{
public:
  void acquire(int *tmp) {
    hp-&gt;p_ = tmp;
  }
  void release() {
    hp-&gt;p_ = nullptr;
  }
  void read() {
    int *tmp = nullptr;
    do
    {
      tmp = ACCESS_ONCE(p);
      Strong_Memory_Barrier();
      acquire(tmp); //封装。这是告诉Writer：我要读，别释放！
    } while (tmp != ACCESS_ONCE(p));//仔细想想，为什么这里还要判断？
    if (nullptr != tmp) { //不妨想想，这里为什么也要判断？
      //it is safe to access *tmp from now on
      cout « *tmp « endl;//没问题~
    }
    //when you finish reading it, just release it .
    release();//其实就是告诉Writer：用完了，可以释放了。
  }
};
int main()
{
  thread t1(&amp;Reader::read, Reader());
  thread t2(&amp;Writer::write, Writer());
  t1.join();
  t2.join();
  return 0;
}
```</p>

<p>总结：</p>

<p>1，对于读线程，每次访问指针前，都通过<strong>acquire</strong>动作，用<strong>Hazard</strong> <strong>Pointer</strong>封装一下待读取指针，此举保护了原始指针，向其他线程宣告，我正在读取它指向的内存，请别释放它。用完就<strong>release</strong>一下。</p>

<p>2，对于写线程，真正释放前，需要检查是否有读线程正在操作它。如何知道？看看自己待释放的指针，有没有存在在读线程的<strong>Hazard</strong> <strong>Pointer</strong>里即可。</p>

<p>至于<strong>52</strong>行，考虑如下情形：读线程刚刚设置了<strong>tmp</strong>指针，还没对它进行保护，就被调度出去；写线程执行<strong>gc</strong>时，发现没有读线程的<strong>Hazard</strong> <strong>Pointer</strong>封装了<strong>tmp</strong>指针，于是将它释放；等读线程重新被调度执行时通过<strong>tmp</strong>进行内存访问，就会导致问题。</p>

<p>至于<strong>53</strong>行，请读者自行分析。</p>

<h2 id="section-1">最后思考</h2>

<p>那么，<strong>Hazard</strong> <strong>Pointer</strong>的内存空间，谁来负责管理？</p>

<p>在实际程序里，一般所需<strong>Hazard</strong> <strong>Pointer</strong>的数量不会太多且较为固定，因此基本上只申请，不释放了。</p>

<h2 id="section-2">参考文献</h2>

<p>https://www.research.ibm.com/people/m/michael/ieeetpds-2004.pdf</p>

<h2 id="section-3">致谢</h2>

<p>感谢<a href="http://weibo.com/hanfooo">韩富晟</a>先生对我的指点，让我加深了对<strong>Hazard</strong> <strong>Pointer</strong>的认识。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux环境多线程编程基础设施]]></title>
    <link href="http://www.yebangyu.org/blog/2015/10/31/linux-parallen-programmming-infrastructure/"/>
    <updated>2015-10-31T18:43:00+08:00</updated>
    <id>http://www.yebangyu.org/blog/2015/10/31/linux-parallen-programmming-infrastructure</id>
    <content type="html"><![CDATA[<p>本文介绍多线程环境下并行编程的基础设施。主要包括：</p>

<blockquote>
  <ul>
    <li>volatile</li>
    <li>__thread</li>
    <li>Memory Barrier</li>
    <li>__sync_synchronize</li>
  </ul>
</blockquote>

<h2 id="volatile">volatile</h2>

<p>编译器有时候为了优化性能，会将一些变量的值缓存到寄存器中，因此如果编译器发现该变量的值没有改变的话，将从寄存器里读出该值，这样可以避免内存访问。</p>

<p>但是这种做法有时候会有问题。如果该变量确实（以某种很难检测的方式）被修改呢？那岂不是读到错的值？是的。在多线程情况下，问题更为突出：当某个线程对一个内存单元进行修改后，其他线程如果从寄存器里读取该变量可能读到老值，未更新的值，错误的值，不新鲜的值。</p>

<!--more-->

<p>如何防止这样错误的“优化”？方法就是给变量加上<strong>volatile</strong>修饰。</p>

<pre><code>volatile int i=10;//用volatile修饰变量i
......//something happened 
int b = i;//强制从内存中读取实时的i的值
</code></pre>

<p><strong>OK</strong>，毕竟<strong>volatile</strong>不是完美的，它也在某种程度上限制了优化。有时候是不是有这样的需求：我要你立即实时读取数据的时候，你就访问内存，别优化；否则，你该优化还是优化你的。能做到吗？</p>

<p>不加<strong>volatile</strong>修饰，那么就做不到前面一点。加了<strong>volatile</strong>，后面这一方面就无从谈起，怎么办？伤脑筋。</p>

<p>其实我们可以这样：</p>

<pre><code>int i = 2; //变量i还是不用加volatile修饰

#define ACCESS_ONCE(x) (* (volatile typeof(x) *) &amp;(x))
</code></pre>

<p>需要实时读取i的值时候，就调用<code>ACCESS_ONCE(i)</code>，否则直接使用i即可。</p>

<p>这个技巧，我是从《<strong>Is parallel programming hard？</strong>》上学到的。</p>

<p>听起来都很好？然而险象环生：<strong>volatile</strong>常被误用，很多人往往不知道或者忽略它的两个特点：在<strong>C/C++</strong>语言里，<strong>volatile</strong>不保证原子性；使用<strong>volatile</strong>不应该对它有任何<strong>Memory Barrier</strong>的期待。</p>

<p>第一点比较好理解，对于第二点，我们来看一个很经典的例子：</p>

<p>```c++
volatile int is_ready = 0;
char message[123];
void thread_A
{
  while(is_ready == 0) 
  {
  }
  //use message;
}
void thread_B
{
  strcpy(message,”everything seems ok”);
  is_ready = 1;
}</p>

<p>```
线程<strong>B</strong>中，虽然<strong>is_ready</strong>有<strong>volatile</strong>修饰，但是这里的<strong>volatile</strong>不提供任何<strong>Memory Barrier</strong>，因此<strong>12</strong>行和<strong>13</strong>行可能被乱序执行，<code>is_ready = 1</code>被执行，而<strong>message</strong>还未被正确设置，导致线程<strong>A</strong>读到错误的值。</p>

<p>这意味着，在多线程中使用<strong>volatile</strong>需要非常谨慎、小心。</p>

<h2 id="thread">__thread</h2>

<p><strong>__thread</strong>是<strong>gcc</strong>内置的用于多线程编程的基础设施。用<strong>__thread</strong>修饰的变量，每个线程都拥有一份实体，相互独立，互不干扰。举个例子：</p>

<p><code>c++
#include&lt;iostream&gt;  
#include&lt;pthread.h&gt;  
#include&lt;unistd.h&gt;  
using namespace std;  
__thread int i = 1;
void* thread1(void* arg);  
void* thread2(void* arg);  
int main()
{  
  pthread_t pthread1;
  pthread_t pthread2;  
  pthread_create(&amp;pthread1, NULL, thread1, NULL);
  pthread_create(&amp;pthread2, NULL, thread2, NULL);
  pthread_join(pthread1, NULL);  
  pthread_join(pthread2, NULL);  
  return 0;  
}  
void* thread1(void* arg)
{  
  cout&lt;&lt;++i&lt;&lt;endl;//输出 2  
  return NULL;
}  
void* thread2(void* arg)
{  
  sleep(1); //等待thread1完成更新
  cout&lt;&lt;++i&lt;&lt;endl;//输出 2，而不是3
  return NULL;
} 
</code></p>

<p>需要注意的是：</p>

<p>1，<strong>__thread</strong>可以修饰全局变量、函数的静态变量，但是无法修饰函数的局部变量。</p>

<p>2，被<strong>__thread</strong>修饰的变量只能在编译期初始化，且只能通过常量表达式来初始化。</p>

<h2 id="memory-barrier">Memory Barrier</h2>

<p>为了优化，现代编译器和<strong>CPU</strong>可能会乱序执行指令。例如：</p>

<p><code>c++
int a = 1;
int b = 2;
a = b + 3;
b = 10;
</code></p>

<p><strong>CPU</strong>乱序执行后，第4行语句和第5行语句的执行顺序可能变为先<code>b=10</code>然后再<code>a=b+3</code></p>

<p>有些人可能会说，那结果不就不对了吗？b为10，a为13？可是正确结果应该是a为5啊。</p>

<p>哦，这里说的是语句的执行，对应的汇编指令不是简单的mov b,10和mov b,a+3。</p>

<p>生成的汇编代码可能是：</p>

<p><code>
movl    b(%rip), %eax ; 将b的值暂存入%eax
movl    $10, b(%rip) ; b = 10
addl    $3, %eax ; %eax加3
movl    %eax, a(%rip) ; 将%eax也就是b+3的值写入a,即 a = b + 3
</code></p>

<p>这并不奇怪，为了优化性能，有时候确实可以这么做。但是在多线程并行编程中，有时候乱序就会出问题。</p>

<p>一个最典型的例子是用锁保护临界区。如果临界区的代码被拉到加锁前或者释放锁之后执行，那么将导致不明确的结果，往往让人不开心的结果。</p>

<p>还有，比如随意将读数据和写数据乱序，那么本来是先读后写，变成先写后读就导致后面读到了脏的数据。因此，<strong>Memory Barrier</strong>就是用来防止乱序执行的。具体说来，<strong>Memory Barrier</strong>包括三种：</p>

<p>1，<strong>acquire barrier</strong>。<strong>acquire barrier</strong>之后的指令不能也不会被拉到该<strong>acquire barrier</strong>之前执行。</p>

<p>2，<strong>release barrier</strong>。<strong>release barrier</strong>之前的指令不能也不会被拉到该<strong>release barrier</strong>之后执行。</p>

<p>3，<strong>full barrier</strong>。以上两种的合集。</p>

<p>所以，很容易知道，加锁，也就是<strong>lock</strong>对应<strong>acquire barrier</strong>；释放锁，也就是<strong>unlock</strong>对应<strong>release barrier</strong>。哦，那么<strong>full barrier</strong>呢？</p>

<h2 id="syncsynchronize">__sync_synchronize</h2>

<p><code>__sync_synchronize</code>就是一种<strong>full barrier</strong>。</p>
]]></content>
  </entry>
  
</feed>
