<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 并行编程 | Yebangyu's Blog]]></title>
  <link href="http://www.yebangyu.org/blog/categories/bing-xing-bian-cheng/atom.xml" rel="self"/>
  <link href="http://www.yebangyu.org/"/>
  <updated>2016-07-12T15:42:02+08:00</updated>
  <id>http://www.yebangyu.org/</id>
  <author>
    <name><![CDATA[Yebangyu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Sequence Lock]]></title>
    <link href="http://www.yebangyu.org/blog/2016/06/26/sequence-lock/"/>
    <updated>2016-06-26T14:24:59+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/06/26/sequence-lock</id>
    <content type="html"><![CDATA[<p>在读多写少(Read Mostly)的场景里，我们可能会使用的同步设施包括：</p>

<blockquote>
  <ul>
    <li>Mutex</li>
    <li>Reader Writer Lock</li>
    <li>Sequence Lock</li>
    <li>Read Copy Update</li>
  </ul>
</blockquote>

<p>前面两种一般人都很清楚了，如雷贯耳、妇孺皆知。如果您对mutex的实现细节有兴趣，建议您阅读我的两篇博客：<a href="http://www.yebangyu.org/blog/2016/03/04/petersonalgorithm/">这篇</a>和<a href="http://www.yebangyu.org/blog/2016/05/26/ticketlock/">这篇</a></p>

<p>从今天起，我们介绍后面两种同步设施。今天我们先介绍Sequence Lock。</p>

<!--more-->

<h2 id="section">基本原理</h2>

<p>我们知道，传统的Reader Writer Lock是reader preference的，可能会产生writer starvation。和Reader Writer Lock不同，sequence lock是writer preference的，writer随时都可以更新临界资源。</p>

<p>sequence lock的精髓在于一个sequence count。当writer在更新时，count为奇数；不存在writer更新时，该count为偶数。</p>

<p>count初始化为一个偶数，比如说0。当writer操作临界资源前，先将count++，这时候count变成奇数；然后writer操作临界资源，完毕后，再count++，这时候count将又恢复为偶数。</p>

<p>对于reader，每次进入临界区前读取count值，如果为偶数，说明没有writer存在，那么它可以进入临界区；如果为奇数，那么它需要等待，不断重试，读取count直到count为偶数。进入临界区读取临界资源后，你知道，从reader进入临界区到试图离开临界区这段时间里，可能writer进来了，因此reader需要重新读取count，看和它进入临界区时的count是否相等，不等的话说明此次读取失败，需要重试。</p>

<h2 id="section-1">基本实现</h2>

<p>```c++
#include<mutex> //c++11的mutex
using namespace std;</mutex></p>

<p>struct SequenceLock
{
  volatile uint64_t sequence_count;
  mutex lock; //这把锁是用于writer们互斥的。保证只有一个writer能更新。和reader无关。
};</p>

<p>static void seqlock_init(SequenceLock &amp;sl)
{
  sl.sequence_count = 0;//初始化为偶数
}</p>

<p>static uint64_t read_seqbegin(SequenceLock &amp;sl)
{
  uint64_t sc = 0;
  while(true) {
    sc = sl.sequence_count;
    CPU_MEMORY_BARRIER();
    if (!(sc &amp; 1)) {
      break; //sc是偶数，说明没有writer，返回
    } 
  }
  return sc;
}</p>

<p>static bool reader_need_retry(SequenceLock &amp;sl, uint64_t oldseq)
{
  uint64_t s = 0;
  CPU_MEMORY_BARRIER();
  s = sl.sequence_count;
  return s != oldseq;
}</p>

<p>static void write_seqlock(SequenceLock &amp;sl)
{
  sl.lock.lock();
  ++sl.sequence_count;//让count变为奇数，和读者声明自己的存在
  CPU_MEMORY_BARRIER();
}</p>

<p>static void write_sequnlock(SequenceLock &amp;sl)
{
  CPU_MEMORY_BARRIER();
  ++sl.sequence_count;//让count恢复为偶数
  sl.lock.unlock();
}</p>

<p>```</p>

<h2 id="section-2">深度思考</h2>

<p>1，sequence lock和reader writer lock相比，有什么区别？</p>

<p>最主要的区别，如上所述，就是writer随时随地可以进行更新，不会出现writer starvation的情况。正因为如此，如果update heavily，那么可能造成reader starvation。然而，正如我们一早所说的，sequence lock用于read mostly的situation。因此，reader starvation几乎不会发生。</p>

<p>reader端并不需要加锁，只在极少情况下需要重试而已。因此，从某种角度来说，sequence lock是一种乐观锁。</p>

<p>2，sequence_count声明为<code>uint32_t</code>是否可以？</p>

<p>看你的writer更新的频率。假如你的writer每小时才更新一次，那么一天更新24次，一个月更新720次，一年才262800次，一百年才26280000次，是没有溢出危险的。如果每纳秒更新一次呢？算算看。</p>

<p>我知道，C语言uint32_max（奇数）再自增1之后溢出会回滚到0（偶数）不会影响到程序的正确性，但是好的程序个人认为不应该对此有依赖。</p>

<p>3，使用sequence lock可能会有什么坑？</p>

<p>假如我们的临界资源是这样的：</p>

<p><code>c++
something *p;
</code></p>

<p>reader进入临界区后读取p，存放在自己的变量something *q里，然后返回。之后writer对p进行了free操作；如果reader之后使用<code>*q</code>将发生错误。对于这种情况，需要使用值拷贝语义，或者通过引入<a href="http://www.yebangyu.org/blog/2015/12/10/introduction-to-hazard-pointer/">hazard pointer</a>等其他机制来避免内存释放问题。不仅如此，实际上在临界区里，reader都不可以使用<code>*p</code>，这是因为和reader writer lock不同，sequence lock是不保证writer的不存在的，也就是说在临界区里，是可能随时有writer对p进行释放等操作的（这才需要读者后面的重试操作嘛），这也是它和读写锁的最大不同。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ticket Lock]]></title>
    <link href="http://www.yebangyu.org/blog/2016/05/26/ticketlock/"/>
    <updated>2016-05-26T19:25:15+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/05/26/ticketlock</id>
    <content type="html"><![CDATA[<h2 id="section">简单回顾</h2>

<p><a href="http://www.yebangyu.org/blog/2016/03/04/petersonalgorithm/">上回</a> 我们介绍了peterson算法来实现spin lock，算法简单，实现简单，但是值得注意和留心的点很多。</p>

<p>粗略说来，peterson算法的主要缺点在于：</p>

<p>1，很难推广到n个线程(n&gt;=3)。原始的算法针对两个线程，如果想应用在多个线程的场景里，需要做一定的修改。</p>

<p>2，peterson算法的动机是仅仅使用load和store来实现互斥访问。然而，我们知道，现代体系结构下，CPU和编译器会对读写操作进行乱序，仅仅依靠读写操作而不使用memory barrier就编写正确的程序非常困难。</p>

<h2 id="ticket-lock">Ticket Lock</h2>

<p>在介绍Ticket Lock之前，我们首先分析一个妇孺皆知、地球人都知道的实现spin lock的方法（伪代码）：</p>

<!--more-->

<p><code>c++
int flag = 0;
void lock()
{
  while (!cas(flag, 0, 1));
  //get lock ! now , flag == 1
}
void unlock()
{
  flag = 0;
}
</code>
上面代码的第四行使用一个CAS原子操作：判断如果flag是否为0，如果为0，将它的值设置为1。判断和设置，所谓的test和set是一个原子操作，返回ture；如果不为0，则不设置，返回false。</p>

<p>这就是大名鼎鼎的<code>test-and-set</code>来实现spin lock。想想看，这种实现方式有什么缺点？</p>

<p>缺点一：不保证公平性，不满足FIFO先来先服务。假如有两个线程在第4行上spin，那么当持有锁的线程释放锁之后，这两个线程谁会成功拿到锁和谁先来spin没有任何直接关系。</p>

<p>缺点二：我们知道，不管CAS操作是否成功，都会产生大量的因为需要保证cache coherency而产生的message，降低性能。因此有一种改进方式：在CAS之前，先读取flag的值，当flag的值为0的时候，再尝试CAS。如下图的伪代码所示：</p>

<p><code>c++
int flag = 0;
void lock()
{
  while(true) {
    if (flag == 0) {
      if (cas(flag, 0, 1)) {
        break;
      }
    }
  }
  //get lock ! now , flag == 1
}
void unlock()
{
  flag = 0;
}
</code></p>

<p>改进后的算法叫做<code>test-and-test-and-set</code>，然而即使经过改进，上面的两个问题依旧存在。在很多场景下，我们希望：</p>

<p>1，保证公平性。</p>

<p>2，原子操作少些，少些，再少些。</p>

<p>3，没有饥饿。</p>

<p>这就涉及到我们要谈到的Ticket Lock。</p>

<p>想想我们去银行排队办业务：先拿个号，然后排队，叫到你的号就是服务你的时候了。没叫到你？老老实实等着吧（这里不考虑关系户走后门插队）。</p>

<p><a href="https://github.com/yebangyu/Soupen/blob/master/src/concurrency/soupen_ticket_spin_lock.h">Soupen</a>中实现了ticket spin lock，这里摘抄如下：</p>

<p><code>
class SoupenTicketSpinLock
{
  public:
    SoupenTicketSpinLock()
    {
      next_id_ = 0;
      service_id_ = 0;
    }
    bool lock()
    {
      uint64_t my_id = FETCH_AND_ADD(&amp;next_id_, 1);
      CPU_BARRIER();
      while(my_id != ACCESS_ONCE(service_id_)) {}
      return true;
    }
    void unlock()
    {
      INC_ATOMIC(&amp;service_id_, 1);
    }
  private:
    uint64_t next_id_;
    uint64_t service_id_;
};
</code>
第11行：获得自己的号，同时把号码递增。其中<code>fetch_and_add</code>是一个原子操作:</p>

<p><code>c++
int fech_and_add(int *p, int inc)
{
  int origin = *p;
  *p += inc;
  return origin;
}
</code>
顺便说一下，也有所谓的<code>add_and_fech</code>：
<code>c++
int add_and_fetch(int *p, int inc)
{
  *p += inc;
  return *p;
}
</code>
区别就在于返回原来的值还是返回更新后的值</p>

<p>第13行：判断是否到自己的号了，否则就一直等待。</p>

<p>第18行：叫下一个人，和下一个人说，轮到你了。</p>

<p>关于<code>CPU_BARRIER</code>、<code>FETCH_AND_ADD</code>、<code>ACCESS_ONCE</code>和<code>INC_ATOMIC</code>的实现，请参考<a href="https://github.com/yebangyu/Soupen/blob/master/src/base/soupen_define.h">Soupen</a>中的相关代码。</p>

<p>公平性：不难看出，先来排队的人将优先获得服务。</p>

<p>性能：不难看出，和之前的不断CAS的版本相比，ticket lock算法中，一次lock调用只有一次原子操作开销。</p>

<p>饥饿：不难看出，每个线程都可以按照自己的排队顺序拿到锁，不会发生饥饿现象。</p>

<p>哈哈，如果过号呢？现实生活里，去银行排队可能因为时间太长不爽闪人了，银行叫人如果连叫三遍还没看到你就会叫下一个人了。</p>

<p>在这里，假如持有锁的线程crash了，来不及调用unlock，那么所有等待锁的线程都将一直spin，除非，哦，除非海量的线程来排队不断自增<code>next_id_</code>导致<code>next_id_</code>溢出回滚，然后重新等于<code>service_id_</code>。</p>

<p>如果持有锁的线程没有crash，它正常释放锁，而叫到的下一个线程之前crash了，那么也会导致所有排队的线程拿不到锁。</p>

<p>顺便说一下，(部分)Linux Kernel的spin lock就是用ticket lock实现的。更多细节可以参考<a href="https://www.ibm.com/developerworks/cn/linux/l-cn-spinlock/">这里</a>。</p>

<p>那么ticket lock是否完美呢？有什么惊人的缺点呢？请看下集。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Peterson算法实现spin lock]]></title>
    <link href="http://www.yebangyu.org/blog/2016/03/04/petersonalgorithm/"/>
    <updated>2016-03-04T22:26:51+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/03/04/petersonalgorithm</id>
    <content type="html"><![CDATA[<p>对spin lock和mutex不熟悉的朋友，可以看<a href="http://www.yebangyu.org/blog/2016/01/24/spinlock-and-mutex/">上篇</a>博客。</p>

<h2 id="section">提出问题</h2>

<p>如何仅仅通过load和store实现spin lock呢？</p>

<p>本文只考虑、只针对只有两个线程的情形。假设这两个线程的id分别为0和1。编程环境为X86体系结构 + Intel CPU + gcc</p>

<!--more-->

<h2 id="section-1">分析问题</h2>

<h3 id="section-2">尝试一：仅使用一个变量</h3>

<p>仅使用一个bool类型变量flag，线程i申请锁时，查看flag是否为1-i，如果不是，说明另外一个线程没有在临界区，申请成功，并把flag的值设置为i。</p>

<p>这种方法的问题在于，检查flag是否为1-i，以及设置flag为i这两步不是原子的，无法仅仅通过load和store来原子实现。（需要CAS等类似的原子操作）</p>

<h3 id="section-3">尝试二：使用两个变量</h3>

<p>根据前面的分析，我们可以使用两个bool变量flag[0]和flag[1]。线程i申请锁时，先把flag[i]设置为true，表示自己试图进入临界区，然后查看flag[1-i]是否为true，如果是，说明另一个线程在临界区，于是spin。</p>

<p>这个方法的问题在于可能发生这样的问题：</p>

<p>线程0把flag[0]设置为true，这时候还没开始检查flag[1]，此时线程1把flag[1]设置为true。</p>

<p>接下去，每个线程都发现对方的flag为true，而实际上两个都没在临界区中，却谁都没法拿到锁，发生starvation现象。</p>

<h3 id="section-4">尝试三：使用三个变量</h3>

<p>在尝试二的基础上，再增加一个变量turn，表示谁先将自己的flag设置为true（仅仅通过那两个flag是没法区分的，想想看，是不是这样的）。因此这个变量可以用来裁决谁取得进入临界区的权利。</p>

<h2 id="section-5">解决问题</h2>

<p>以上尝试三所描述的方法，就是大名鼎鼎的peterson算法的雏形了。简单实现如下（注意，本文的平台是x86体系结构 + Intel CPU + gcc）：</p>

<p><code>c++
class PetersonSpinLock
{
  public:
    PetersonSpinLock()
    {
      flags_[0] = false;
      flags_[1] = false;
      turn_ = false;//initial value does not matter
    }
    bool lock(int thread_id)
    {
      int other = !thread_id;
      flags_[thread_id] = true; 
      COMPILER_BARRIER();
      turn_ = thread_id;
      CPU_BARRIER();// essential
      while(flags_[other] &amp;&amp; turn_ == thread_id) {
        CPU_RELAX();//spin
      }
      //get lock successfully
      return true;
    }
    bool unlock(int thread_id)
    {
      flags_[thread_id] = false;
      return true;
    }
  private:
    volatile bool flags_[2];
    volatile bool turn_;
};
</code></p>

<p>以下是对peterson算法的思考和讨论。在看我的分析之前，请自己尝试思考以下问题：（温馨提示：在C/C++中，if条件判断是短路求值的。也就是说对于if(A &amp;&amp; B)，一旦知道A是false，那么B将不用evaluate了）</p>

<blockquote>
  <ul>
    <li>peterson算法如何防止starvation的发生？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>peterson算法如何防止两个线程同时进入临界区？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>代码13行和15行能否调换执行顺序？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>代码15行能否改为<code>turn_ = !thread_id</code> ？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>16行的cpu 级别的memory barrier是否必要？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>实现（针对两个线程的）peterson算法所需最少空间为多少？</li>
  </ul>
</blockquote>

<p>思考了没？下面我们来分析讨论一下：</p>

<h3 id="petersonstarvation">peterson算法如何防止starvation的发生？</h3>

<p>假设某时刻两个线程都在spin，也就是17行中while的条件对两个线程都成立，也就是说：</p>

<p>flag_[0] == true 并且 trun_ == 0 并且 flag_[1] == true 并且turn_ == 1</p>

<p>但是turn_只能有一个值，矛盾。</p>

<h3 id="peterson">peterson算法如何防止两个线程同时进入临界区？</h3>

<p>如果两者同时进入临界区，说明17行中的while判断对两个线程都为false，也就是说</p>

<p>flag_[1] == false 或者 turn _ == 1</p>

<p>同时</p>

<p>flag_[0] == false 或者 turn_ == 0</p>

<p>因此只有四种情形：</p>

<p>flag_[1] == false  &amp;&amp; flag_[0] == false  与13行矛盾</p>

<p>flag_[1] == false  &amp;&amp; turn_ == 0  与13行矛盾</p>

<p>turn_ == 1 &amp;&amp; flag_[0] == false 与13行矛盾</p>

<p>turn _ == 1 &amp;&amp; turn _ == 0 不可能发生</p>

<p>而一旦例如说，线程0，进入临界区后，线程1会因为turn_的值而spin，直到线程0通过unlock将flag_[0]设置为false。</p>

<p>因此，13、15两行的顺序很重要。是这样的吗？接着往下看。</p>

<h3 id="section-6">代码13行和15行能否调换执行顺序？</h3>

<p>不可以，否则可能发生两个线程同时进入临界区。</p>

<p>考虑以下情形：</p>

<p>线程0执行turn_ = 0</p>

<p>线程1执行turn_ = 1</p>

<p>线程1执行flag_[1] = true</p>

<p>线程1执行17行的判断，因为flag_[0]为false，所以线程1进入临界区。</p>

<p>线程0执行flag_[0] = true</p>

<p>线程0执行17行判断，此时turn_等于1，所以线程0也进入临界区。</p>

<p>因此13行和15行执行顺序不可以交换；而这两个都是store操作，在X86 Intel CPU下，cpu不会乱序执行它们，因此只需要在14行增加一个compiler级别的memory barrier，防止编译器乱序即可。</p>

<h3 id="turn--threadid">代码15行能否改为<code>turn_ = !thread_id</code></h3>

<p>可以。只是如果15行改为<code>turn_ = !thread_id</code>，那么17行需要将<code>turn_ == thread_id</code>也改为<code>turn_ == !thread_id</code>。也就是说turn_的初始值是什么并不重要，turn_设置成什么值也不太重要，重要的是通过turn_能区分出谁先尝试申请锁。</p>

<h3 id="cpu-memory-barrier">16行的cpu 级别的Memory Barrier是否必要？</h3>

<p>非常必要。否则17行对flags_[other]的读取（判断）操作可能和15行发生乱序（写读乱序。而13、15属于写写，是不会被CPU乱序执行的，不用加cpu 级别的memory barrier），最后可能导致两个线程同时进入临界区。这点，请读者务必自己亲自分析。非常重要！</p>

<p>不加Memory Barrier，乱序后，考虑以下情形：</p>

<p>线程0判断flag_[1]，发现为false（此时线程1还没开始调用lock函数，flag_[1]还是它的初始值false），进入临界区。</p>

<p>线程1判断flag_[0]，发现为true</p>

<p>线程1执行<code>turn_ = 1</code></p>

<p>线程0执行<code>turn_ = 0</code></p>

<p>线程1执行17行判断，此时turn_等于0，所以线程1也进入临界区。</p>

<h3 id="peterson-1">实现（针对两个线程的）peterson算法所需最少空间为多少？</h3>

<p>3个bit足矣。两个flag_两个bit，turn_也只需要1个bit。</p>

<h2 id="section-7">附录：</h2>

<p>在X86下，<code>CPU_BARRIER</code>和<code>CPU_RELAX</code>以及<code>COMPILER_BARRIER</code>可以用gcc内置feature，通过宏来实现：</p>

<p><code>c++
#define CPU_BARRIER() __sync_synchronize()
#define COMPILER_BARRIER() __asm__ __volatile__("" : : : "memory")
#define CPU_RELAX() __asm__ __volatile__("pause": : :"memory")
</code></p>

<p>18行不用CPU_RELAX而是简单的一个分号行吗？可以的。不过加了CPU_RELAX可以提高性能、节能减排。</p>

<h2 id="section-8">致谢</h2>

<p>本文发出后，微博网友@finalpatch 指出应在代码的29、30行加上volatile。非常感谢。</p>

<p>本文发出后，微博网友@linyvxiang 指出了文中的两处笔误。非常感谢。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Materials In Concurrency Programming]]></title>
    <link href="http://www.yebangyu.org/blog/2016/02/16/materials-in-concurrency-programming/"/>
    <updated>2016-02-16T23:36:28+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/02/16/materials-in-concurrency-programming</id>
    <content type="html"><![CDATA[<h2 id="prerequisite">Prerequisite</h2>

<p>对CPU、内存、Cache有一个很好的认识，对学习并发编程有很大的帮助。</p>

<p><a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">What Every Programmer Should Know About Memory</a></p>

<p><a href="http://www.amazon.com/Consistency-Coherence-Synthesis-Lectures-Architecture/dp/1608455645">A Primer on Memory Consistency and Cache Coherence</a></p>

<!--more-->

<h2 id="textbook">Textbook</h2>

<p><a href="https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a></p>

<p>Paul大叔的神作。</p>

<p>优点：</p>

<p>1，很全面，除了介绍lock的实现、RCU、Transaction Memory等等之外，还包括一些并发程序设计的其他知识，比如如何验证、如何调试等。</p>

<p>个人非常喜欢第14章和附录C，分别详细介绍了什么是Memory Barrier以及为什么需要Memory Barrier。强烈推荐！</p>

<p>2，很正派。这里面介绍的技术都非常通用，普遍适用，没有太多的黑科技。比如书中重点强调的partition，就是一种非常重要、非常scientific的思想。</p>

<p>3，很幽默。真的，很幽默。</p>

<p>缺点：因为正派，所以就没有介绍lock free这种很tricky的黑科技，算是不足吧。</p>

<p>个人喜爱程度：5颗星</p>

<p><a href="http://www.amazon.com/The-Multiprocessor-Programming-Revised-Reprint/dp/0123973376">The Art of Multiprocessor Programming</a></p>

<p>被很多人推崇。第一版有很多错误，作者随后推出了revised版本。</p>

<p>优点：市面上目前能见到的唯一一本包括大量Lock Free Data Structure实现的书籍。</p>

<p>缺点：</p>

<p>1，Java语言实现。个人固执认为应该用C或者C++</p>

<p>2，没有介绍RCU等重要内容</p>

<p>3，不详细。可能是我个人实力不行，感觉这本书讲的并不好，看完还是得看论文才懂。</p>

<p>个人喜爱程度：3颗星</p>

<p><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00499ED1V01Y201304CAC023">Shared Memory Synchronization</a></p>

<p>优点：</p>

<p>1，很新。2013年的书</p>

<p>2，选题不错。综合了上面两本</p>

<p>缺点：</p>

<p>1，鸡肋。初学者看了云里雾里，高手没必要看。</p>

<p>是作者实力不够吗？恐怕不是。作者Michael L. Scott是程序语言设计和并发编程的大拿。</p>

<p>是作者表述能力不行吗？恐怕不是。他写有一本非常著名和畅销的书籍：《Programming Language Pragmatics》</p>

<p>这本书偏综述＋lecture notes性质，估计和这系列丛书的定位有关。</p>

<p>2，没有中文版，没有英文影印版，很难下到pdf。苦逼穷学生想阅读的话基本上只能去amazon.com购买原版</p>

<p>个人喜爱程度：1颗星</p>

<h2 id="blog">Blog</h2>

<p><a href="http://preshing.com/">Jeff Preshing’s Blog</a></p>

<p><a href="http://www.cliffc.org/blog/">Cliff Click’s Blog</a></p>

<p><a href="http://www.yebangyu.org">Yebangyu’s Blog</a></p>

<h2 id="course">Course</h2>

<p><a href="http://15418.courses.cs.cmu.edu/spring2016/">Parallel Computer Architecture and Programming @ CMU</a></p>

<h2 id="paper">Paper</h2>

<h3 id="linked-list--skip-list">Linked List &amp; Skip List</h3>

<p><a href="https://timharris.uk/papers/2001-disc.pdf">A Pragmatic Implementation of Non-Blocking Linked-Lists</a></p>

<p><a href="http://www.cse.yorku.ca/~ruppert/papers/lfll.pdf">Lock Free Linked Lists and Skip Lists</a></p>

<p><a href="http://www.cse.yorku.ca/~ruppert/Mikhail.pdf">Lock Free Linked Lists and Skip Lists</a></p>

<p><a href="http://cs.ucf.edu/~dcm/Teaching/COT4810-Spring2011/Literature/SplitOrderedLists.pdf">Split-Ordered Lists: Lockfree Extensible Hash Tables</a></p>

<p><a href="http://cs.brown.edu/~mph/LevHLS06/OPODIS2006-BA.pdf">A Provably Correct Scalable Concurrent Skip List</a></p>

<h3 id="stack">Stack</h3>

<p><a href="http://www.cs.bgu.ac.il/~hendlerd/papers/scalable-stack.pdf">A Scalable Lock Free Stack Algorithm</a></p>

<h3 id="queue">Queue</h3>

<p><a href="http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf">Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms</a></p>

<p><a href="http://www.non-blocking.com/download/SunT03_PQueue_TR.pdf">Fast and Lock Free Concurrent Priority Queues for Multi-Thread Systems</a></p>

<p><a href="http://people.csail.mit.edu/edya/publications/OptimisticFIFOQueue-DISC2004.pdf">An Optimistic Approach to Lock Free FIFO Queues</a></p>

<h3 id="hash-map">Hash Map</h3>

<p><a href="http://www.win.tue.nl/~jfg/articles/CS-Report03-03.pdf">Efficient Almost Wait Free Parallel Accessible Dynamic Hash-tables</a></p>

<p><a href="http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-639.pdf">Non-Blocking Hash-Tables With Open Addressing</a></p>

<p><a href="http://cs.brown.edu/~mph/HellerHLMSS05/2005-OPODIS-Lazy.pdf">A Lazy Concurrent List-Based Set Algorithm</a></p>

<p><a href="http://www.research.ibm.com/people/m/michael/spaa-2002.pdf">High Performance Dynamic Lock-Free Hash Tables and List-Based Sets</a></p>

<h3 id="cuckoo-hash-map">Cuckoo Hash Map</h3>

<p><a href="http://excess-project.eu/publications/published/CuckooHashing_ICDCS.pdf">Lock-free Cuckoo Hashing</a></p>

<h3 id="b-tree">B+ Tree</h3>

<p><a href="http://www.cs.technion.ac.il/~erez/Papers/lfbtree-full.pdf">A Lock-Free B+ Tree</a></p>

<p><a href="http://www.cs.technion.ac.il/~anastas/lfbtree-spaa.pdf">A Lock-Free B+ Tree</a></p>

<h3 id="others">Others</h3>

<p><a href="https://www.research.ibm.com/people/m/michael/ieeetpds-2004.pdf">Hazard Pointers: Safe Memory Reclamation For Lock-Free Objects</a></p>

<p><a href="http://www.grame.fr/ressources/publications/fober-JIM2002.pdf">Lock Free Techniques for Concurrent Access to Shared Objects</a></p>

<p><a href="http://www.cs.rochester.edu/~scott/papers/1998_JPDC_nonblocking.pdf">Non-Blocking Algorithms and Preemption-Safe Locking on Multiprogrammed Shared Memory Multiprocessors</a></p>

<p><a href="http://cs.brown.edu/people/mph/HerlihyLM03/main.pdf">Obstruction-Free Synchronization: Double-Ended Queues as an Example</a></p>

<p><a href="http://www.research.ibm.com/people/m/michael/podc-2002.pdf">Safe Memory Reclamation for Dynamic Lock Free Objects Using Atomic Reads and Writes</a></p>

<p><a href="http://www.ece.uc.edu/~paw/classes/ece975/sp2010/papers/herlihy-05.pdf">Non-blocking Memory Management Support for Dynamic-Sized Data Structures</a></p>

<p><a href="http://cs.brown.edu/~mph/DohertyHLM04/ft_gateway.cfm.pdf">Bringing Practical Lock Free Synchronization to 64Bit Applications</a></p>

<p><a href="https://www.research.ibm.com/people/m/michael/pldi-2004.pdf">Scalable Lock-Free Dynamic Memory Allocation</a></p>

<p><a href="http://research.microsoft.com/pubs/209106/paper.pdf">Are Lock-Free Concurrent Algorithms Practically Wait-Free</a></p>

<p><a href="http://www.cl.cam.ac.uk/~pes20/cpp/popl085ap-sewell.pdf">Mathematizing C++ Concurrency</a></p>

<h2 id="pages">Pages</h2>

<p><a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p>

<p><a href="http://jakob.engbloms.se/archives/65">Dekker’s Algorithm Does not Work, as Expected</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[多线程内存问题分析之mprotect方法]]></title>
    <link href="http://www.yebangyu.org/blog/2016/02/01/detectmemoryghostinmultithread/"/>
    <updated>2016-02-01T22:24:25+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/02/01/detectmemoryghostinmultithread</id>
    <content type="html"><![CDATA[<p>多线程中的内存问题，一直被认为是噩梦般的存在，几乎只有高手、大仙才能解决。除了大量的打log、gdb调试、code review以及依靠多年的经验和直觉之外，有没有一些分析的手段和工具呢？答案是肯定的。本文首先介绍其中的一种：mprotect大法。通过mprotect，保护特定的感兴趣的内存，当有线程改写该区域时，会产生一个中断，我们在中断处理函数中把调用栈等信息打印出来。这是大概的思路，不过其中的问题很多，我们慢慢道来。</p>

<!--more-->

<h2 id="section">原理</h2>

<h3 id="mprotect">mprotect函数</h3>

<p>mprotect函数的原型如下：</p>

<p>int mprotect(const void *addr, size_t len, int prot);</p>

<p>其中addr是待保护的内存首地址，必须按页对齐；len是待保护内存的大小，必须是页的整数倍，prot代表模式，可能的取值有PROT_READ（表示可读）、PROT_WRITE（可写）等。</p>

<p>不同体系结构和操作系统，一页的大小不尽相同。如何获得页大小呢？通过PAGE_SIZE宏或者getpagesize()系统调用即可。</p>

<h3 id="section-1">定制中断处理函数</h3>

<p>当线程试图对我们已保护（成只读）的内存进行篡改时，默认情况下程序会收到SIGSEGV错误而退出。能不能不退出并且把相应的调用栈打印出来分析？当然可以。通过如下代码注册你定制的中断处理函数即可：</p>

<pre><code>struct sigaction act;
act.sa_sigaction = your_handler;
sigemptyset(&amp;act.sa_mask);
act.sa_flags = SA_SIGINFO;
if(sigaction(SIGSEGV, &amp;act, NULL) == -1) {
  perror("Register hanlder failed");
  exit(EXIT_FAILURE);
}
</code></pre>

<p>这样，控制流就会到达你编写的your_handler函数上。而your_handler的函数原型是：</p>

<p>void your_handler(int sig, siginfo_t *si, void *unused)；</p>

<p>编写your_handler函数即可？是的，不过这里面有两个注意事项：</p>

<p>1，中断处理函数里不应该调用内存分配函数，否则可能会引起double fault。因此，不适合调用backtrace_symbols（内部会动态分配内存），而是通过backtrace_symbols_fd直接将调用栈信息直接刷到文件中。</p>

<p>2，中断处理函数中应该恢复被保护内存为可写，否则会引起死循环。（再次中断并进入咱们编写的函数）</p>

<h3 id="section-2">封装</h3>

<p>为了方便使用，我封装了一个类，供参考：
<code>c++
#include &lt;fcntl.h&gt;
#include &lt;signal.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdint.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/user.h&gt;
#include &lt;execinfo.h&gt;
class MemoryDetector
{
public:
  typedef void (*segv_handler) (int sig, siginfo_t *si, void *unused);
  static void init(const char *path)
  {
    register_handler(handler);
    fd_ = open(path, O_RDWR|O_CREAT, 777);
  }
  static int protect(void *p, int len)
  {
    address_ = reinterpret_cast&lt;uint64_t&gt;(p);
    len_ = len;
    uint64_t start_address = (address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ);
  }
  static int umprotect(void *p, int len)
  {
    uint64_t tmp_address_ = reinterpret_cast&lt;uint64_t&gt;(p);
    uint64_t start_address = (tmp_address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ | PROT_WRITE);
  }
  static int umprotect()
  {
    uint64_t start_address = (address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ | PROT_WRITE);
  }
  static void finish()
  {
    close(fd_);
  }
private:
  static void register_handler(segv_handler sh)
  {
    struct sigaction act;
    act.sa_sigaction = sh;
    sigemptyset(&amp;act.sa_mask);
    act.sa_flags = SA_SIGINFO;
    if(sigaction(SIGSEGV, &amp;act, NULL) == -1){
      perror("Register hanlder failed");
      exit(EXIT_FAILURE);
    }
  }
  static void handler(int sig, siginfo_t *si, void *unused)
  {
    uint64_t address = reinterpret_cast&lt;uint64_t&gt;(si-&gt;si_addr);
    if (address &gt;= address_ &amp;&amp; address &lt; address_ + len_) {
      umprotect(si-&gt;si_addr, PAGE_SIZE);
      my_backtrace();
    }
  }
  static void my_backtrace()
  {
    const int N = 100;
    void* array[100];
    size_t size = backtrace(array, N);
    backtrace_symbols_fd(array, size, fd_);
  }
  static uint64_t address_;
  static int len_;
  static int fd_;
};
</code></p>

<p>这个封装还存在一些问题，比如缺少错误处理，待保护内存必须在一页内等。读者诸君可以根据需要自行完善。</p>

<h2 id="section-3">实战</h2>

<p>来个例子,实战一下吧
<code>c++
#include "test.h" //就是上面封装的MemoryDetector类
#include &lt;thread&gt;
using namespace std;
uint64_t MemoryDetector::address_ = 0;
int MemoryDetector::len_ = 0;
int MemoryDetector::fd_ = 0;
///////////////////////////////////////
int *p = NULL;
void g()
{
  usleep(2000000);
  char *q = reinterpret_cast&lt;char *&gt;(p);
  *(q+2) = 111;//非法篡改！！！
}
void f()
{
  p = new int(1);
  MemoryDetector::protect(p, 4);
}
int main()
{
  const char *path = "result.tmp";//调用栈信息存放路径
  MemoryDetector::init(path);
  std::thread t1(f);
  std::thread t2(g);
  t1.join();
  t2.join();
  MemoryDetector::finish();
  return 0;
}
</code>
用如下方式编译链接以上程序：</p>

<pre><code>g++ -g -rdynamic -std=c++11 -pthread  test.cpp -o test
</code></pre>

<p>程序运行结束后，打开result.tmp文件，看到如下内容：</p>

<pre><code>./test(_ZN14MemoryDetector12my_backtraceEv+0x26)[0x405ce8]
./test(_ZN14MemoryDetector7handlerEiP7siginfoPv+0x60)[0x405cc0]
/lib64/libpthread.so.0[0x339a80f500]
./test(_Z1gv+0x25)[0x405909]
./test(_ZNSt6thread5_ImplIPFvvEE6_M_runEv+0x16)[0x406e2c]
/usr/lib64/libstdc++.so.6[0x3a6f6b6490]
/lib64/libpthread.so.0[0x339a807851]
/lib64/libc.so.6(clone+0x6d)[0x339a4e767d]
</code></pre>

<p>注意其中的第四行：./test(_Z1gv+0x25)[0x405909]。使用addr2line命令：</p>

<pre><code>addr2line -e test 0x405909
</code></pre>

<p>获得非法篡改的代码位置：</p>

<p>/home/yebangyu/test.cpp:13</p>

<p>真相大白了。</p>

<h2 id="section-4">感谢</h2>

<p>我最早知道这个方法，是从我主管<a href="http://weibo.com/yangzhifeng83">杨志丰</a>先生那儿以及他的<a href="http://blog.csdn.net/killmice/article/details/38443343">这篇</a>文章。</p>
]]></content>
  </entry>
  
</feed>
