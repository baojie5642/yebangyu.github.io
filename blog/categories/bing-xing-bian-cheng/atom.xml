<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 并行编程 | Yebangyu's Blog]]></title>
  <link href="http://www.yebangyu.org/blog/categories/bing-xing-bian-cheng/atom.xml" rel="self"/>
  <link href="http://www.yebangyu.org/"/>
  <updated>2016-03-05T16:31:49+08:00</updated>
  <id>http://www.yebangyu.org/</id>
  <author>
    <name><![CDATA[Yebangyu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Peterson算法实现spin lock]]></title>
    <link href="http://www.yebangyu.org/blog/2016/03/04/petersonalgorithm/"/>
    <updated>2016-03-04T22:26:51+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/03/04/petersonalgorithm</id>
    <content type="html"><![CDATA[<p>对spin lock和mutex不熟悉的朋友，可以看<a href="http://www.yebangyu.org/blog/2016/01/24/spinlock-and-mutex/">上篇</a>博客。</p>

<h2 id="section">提出问题</h2>

<p>如何仅仅通过load和store实现spin lock呢？</p>

<p>本文只考虑、只针对只有两个线程的情形。假设这两个线程的id分别为0和1。编程环境为X86体系结构 + Intel CPU + gcc</p>

<!--more-->

<h2 id="section-1">分析问题</h2>

<h3 id="section-2">尝试一：仅使用一个变量</h3>

<p>仅使用一个bool类型变量flag，线程i申请锁时，查看flag是否为1-i，如果不是，说明另外一个线程没有在临界区，申请成功，并把flag的值设置为i。</p>

<p>这种方法的问题在于，检查flag是否为1-i，以及设置flag为i这两步不是原子的，无法仅仅通过load和store来原子实现。（需要CAS等类似的原子操作）</p>

<h3 id="section-3">尝试二：使用两个变量</h3>

<p>根据前面的分析，我们可以使用两个bool变量flag[0]和flag[1]。线程i申请锁时，先把flag[i]设置为true，表示自己试图进入临界区，然后查看flag[1-i]是否为true，如果是，说明另一个线程在临界区，于是spin。</p>

<p>这个方法的问题在于可能发生这样的问题：</p>

<p>线程0把flag[0]设置为true，这时候还没开始检查flag[1]，此时线程1把flag[1]设置为true。</p>

<p>接下去，每个线程都发现对方的flag为true，而实际上两个都没在临界区中，却谁都没法拿到锁，发生starvation现象。</p>

<h3 id="section-4">尝试三：使用三个变量</h3>

<p>在尝试二的基础上，再增加一个变量turn，表示谁先将自己的flag设置为true（仅仅通过那两个flag是没法区分的，想想看，是不是这样的）。因此这个变量可以用来裁决谁取得进入临界区的权利。</p>

<h2 id="section-5">解决问题</h2>

<p>以上尝试三所描述的方法，就是大名鼎鼎的peterson算法的雏形了。简单实现如下（注意，本文的平台是x86体系结构 + Intel CPU + gcc）：</p>

<p><code>c++
class PetersonSpinLock
{
  public:
    PetersonSpinLock()
    {
      flags_[0] = false;
      flags_[1] = false;
      turn_ = false;//initial value does not matter
    }
    bool lock(int thread_id)
    {
      int other = !thread_id;
      flags_[thread_id] = true; 
      turn_ = thread_id;
      CPU_BARRIER();// essential
      while(flags_[other] &amp;&amp; turn_ == thread_id) {
        CPU_RELAX();//spin
      }
      //get lock successfully
      return true;
    }
    bool unlock(int thread_id)
    {
      flags_[thread_id] = false;
      return true;
    }
  private:
    volatile bool flags_[2];
    volatile bool turn_;
};
</code></p>

<p>以下是对peterson算法的思考和讨论。在看我的分析之前，请自己尝试思考以下问题：（温馨提示：在C/C++中，if条件判断是短路求值的。也就是说对于if(A &amp;&amp; B)，一旦知道A是false，那么B将不用evaluate了）</p>

<blockquote>
  <ul>
    <li>peterson算法如何防止starvation的发生？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>peterson算法如何防止两个线程同时进入临界区？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>代码13行和14行能否调换执行顺序？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>代码14行能否改为<code>turn_ = !thread_id</code> ？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>15行的cpu 级别的memory barrier是否必要？</li>
  </ul>
</blockquote>

<blockquote>
  <ul>
    <li>实现（针对两个线程的）peterson算法所需最少空间为多少？</li>
  </ul>
</blockquote>

<p>思考了没？下面我们来分析讨论一下：</p>

<h3 id="petersonstarvation">peterson算法如何防止starvation的发生？</h3>

<p>假设某时刻两个线程都在spin，也就是16行中while的条件对两个线程都成立，也就是说：</p>

<p>flag_[0] == true 并且 trun_ == 0 并且 flag_[1] == true 并且turn_ == 1</p>

<p>但是turn_只能有一个值，矛盾。</p>

<h3 id="peterson">peterson算法如何防止两个线程同时进入临界区？</h3>

<p>如果两者同时进入临界区，说明16行中的while判断对两个线程都为false，也就是说</p>

<p>flag_[1] == false 或者 turn _ == 1</p>

<p>同时</p>

<p>flag_[0] == false 或者 turn_ == 0</p>

<p>因此只有四种情形：</p>

<p>flag_[1] == false  &amp;&amp; flag_[0] == false  与13行矛盾</p>

<p>flag_[1] == false  &amp;&amp; turn_ == 0  与13行矛盾</p>

<p>turn_ == 1 &amp;&amp; flag_[0] == false 与13行矛盾</p>

<p>turn _ == 1 &amp;&amp; turn _ == 0 不可能发生</p>

<p>而一旦例如说，线程0，进入临界区后，线程1会因为turn_的值而spin，直到线程0通过unlock将flag_[0]设置为false。</p>

<p>因此，13、14两行的顺序很重要。是这样的吗？接着往下看。</p>

<h3 id="section-6">代码13行和14行能否调换执行顺序？</h3>

<p>不可以，否则可能发生两个线程同时进入临界区。</p>

<p>考虑以下情形：</p>

<p>线程0执行turn_ = 0</p>

<p>线程1执行turn_ = 1</p>

<p>线程1执行flag_[1] = true</p>

<p>线程1执行16行的判断，因为flag_[0]为false，所以线程1进入临界区。</p>

<p>线程0执行flag_[0] = true</p>

<p>线程0执行16行判断，此时turn_等于1，所以线程0也进入临界区。</p>

<h3 id="turn--threadid">代码14行能否改为<code>turn_ = !thread_id</code></h3>

<p>可以。只是如果14行改为<code>turn_ = !thread_id</code>，那么16行需要将<code>turn_ == thread_id</code>也改为<code>turn_ == !thread_id</code>。也就是说turn_的初始值是什么并不重要，turn_设置成什么值也不太重要，重要的是通过turn_能区分出谁先尝试申请锁。</p>

<h3 id="cpu-memory-barrier">15行的cpu 级别的Memory Barrier是否必要？</h3>

<p>非常必要。否则16行对flags_[other]的读取（判断）操作可能和14行发生乱序（写读乱序。而13、14属于写写，是不会乱序的，不用加barrier），最后可能导致两个线程同时进入临界区。这点，请读者务必自己亲自分析。非常重要！</p>

<p>不加Memory Barrier，乱序后，考虑以下情形：</p>

<p>线程0判断flag_[1]，发现为false（此时线程1还没开始调用lock函数，flag_[1]还是它的初始值false），进入临界区。</p>

<p>线程1判断flag_[0]，发现为true</p>

<p>线程1执行<code>turn_ = 1</code></p>

<p>线程0执行<code>turn_ = 0</code></p>

<p>线程1执行16行判断，此时turn_等于0，所以线程1也进入临界区。</p>

<h3 id="peterson-1">实现（针对两个线程的）peterson算法所需最少空间为多少？</h3>

<p>3个bit足矣。两个flag_两个bit，turn_也只需要1个bit。</p>

<p>下次，我们将讨论peterson算法的拓展，用于n个线程的情形。</p>

<h2 id="section-7">附录：</h2>

<p>在X86下，<code>CPU_BARRIER</code>和<code>CPU_RELAX</code>可以用gcc内置feature，通过宏来实现：</p>

<p><code>c++
#define CPU_BARRIER() __sync_synchronize()
#define CPU_RELAX() __asm__ __volatile__("pause\n": : :"memory")
</code></p>

<p>17行不用CPU_RELAX而是简单的一个分号行吗？可以的。不过加了CPU_RELAX可以提高性能、节能减排。</p>

<h2 id="section-8">致谢</h2>

<p>本文发出后，微博网友@finalpatch 指出应在代码的28、29行加上volatile。非常感谢。</p>

<p>本文发出后，微博网友@linyvxiang 指出了文中的两处笔误。非常感谢。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Materials In Concurrency Programming]]></title>
    <link href="http://www.yebangyu.org/blog/2016/02/16/materials-in-concurrency-programming/"/>
    <updated>2016-02-16T23:36:28+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/02/16/materials-in-concurrency-programming</id>
    <content type="html"><![CDATA[<h2 id="prerequisite">Prerequisite</h2>

<p>对CPU、内存、Cache有一个很好的认识，对学习并发编程有很大的帮助。</p>

<p><a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">What Every Programmer Should Know About Memory</a></p>

<p><a href="http://www.amazon.com/Consistency-Coherence-Synthesis-Lectures-Architecture/dp/1608455645">A Primer on Memory Consistency and Cache Coherence</a></p>

<!--more-->

<h2 id="textbook">Textbook</h2>

<p><a href="https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a></p>

<p>Paul大叔的神作。</p>

<p>优点：</p>

<p>1，很全面，除了介绍lock的实现、RCU、Transaction Memory等等之外，还包括一些并发程序设计的其他知识，比如如何验证、如何调试等。</p>

<p>个人非常喜欢第14章和附录C，分别详细介绍了什么是Memory Barrier以及为什么需要Memory Barrier。强烈推荐！</p>

<p>2，很正派。这里面介绍的技术都非常通用，普遍适用，没有太多的黑科技。比如书中重点强调的partition，就是一种非常重要、非常scientific的思想。</p>

<p>3，很幽默。真的，很幽默。</p>

<p>缺点：因为正派，所以就没有介绍lock free这种很tricky的黑科技，算是不足吧。</p>

<p>个人喜爱程度：5颗星</p>

<p><a href="http://www.amazon.com/The-Multiprocessor-Programming-Revised-Reprint/dp/0123973376">The Art of Multiprocessor Programming</a></p>

<p>被很多人推崇。第一版有很多错误，作者随后推出了revised版本。</p>

<p>优点：市面上目前能见到的唯一一本包括大量Lock Free Data Structure实现的书籍。</p>

<p>缺点：</p>

<p>1，Java语言实现。个人固执认为应该用C或者C++</p>

<p>2，没有介绍RCU等重要内容</p>

<p>3，不详细。可能是我个人实力不行，感觉这本书讲的并不好，看完还是得看论文才懂。</p>

<p>个人喜爱程度：3颗星</p>

<p><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00499ED1V01Y201304CAC023">Shared Memory Synchronization</a></p>

<p>优点：</p>

<p>1，很新。2013年的书</p>

<p>2，选题不错。综合了上面两本</p>

<p>缺点：</p>

<p>1，鸡肋。初学者看了云里雾里，高手没必要看。</p>

<p>是作者实力不够吗？恐怕不是。作者Michael L. Scott是程序语言设计和并发编程的大拿。</p>

<p>是作者表述能力不行吗？恐怕不是。他写有一本非常著名和畅销的书籍：《Programming Language Pragmatics》</p>

<p>这本书偏综述＋lecture notes性质，估计和这系列丛书的定位有关。</p>

<p>2，没有中文版，没有英文影印版，很难下到pdf。苦逼穷学生想阅读的话基本上只能去amazon.com购买原版</p>

<p>个人喜爱程度：1颗星</p>

<h2 id="blog">Blog</h2>

<p><a href="http://preshing.com/">Jeff Preshing’s Blog</a></p>

<p><a href="http://www.cliffc.org/blog/">Cliff Click’s Blog</a></p>

<p><a href="http://www.yebangyu.org">Yebangyu’s Blog</a></p>

<h2 id="course">Course</h2>

<p><a href="http://www.cs.rice.edu/~johnmc/comp522/lecture-notes/">Multicore Computing</a></p>

<h2 id="paper">Paper</h2>

<h3 id="linked-list--skip-list">Linked List &amp; Skip List</h3>

<p><a href="https://timharris.uk/papers/2001-disc.pdf">A Pragmatic Implementation of Non-Blocking Linked-Lists</a></p>

<p><a href="http://www.cse.yorku.ca/~ruppert/papers/lfll.pdf">Lock Free Linked Lists and Skip Lists</a></p>

<p><a href="http://www.cse.yorku.ca/~ruppert/Mikhail.pdf">Lock Free Linked Lists and Skip Lists</a></p>

<p><a href="http://cs.ucf.edu/~dcm/Teaching/COT4810-Spring2011/Literature/SplitOrderedLists.pdf">Split-Ordered Lists: Lockfree Extensible Hash Tables</a></p>

<p><a href="http://cs.brown.edu/~mph/LevHLS06/OPODIS2006-BA.pdf">A Provably Correct Scalable Concurrent Skip List</a></p>

<h3 id="stack">Stack</h3>

<p><a href="http://www.cs.bgu.ac.il/~hendlerd/papers/scalable-stack.pdf">A Scalable Lock Free Stack Algorithm</a></p>

<h3 id="queue">Queue</h3>

<p><a href="http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf">Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms</a></p>

<p><a href="http://www.non-blocking.com/download/SunT03_PQueue_TR.pdf">Fast and Lock Free Concurrent Priority Queues for Multi-Thread Systems</a></p>

<p><a href="http://people.csail.mit.edu/edya/publications/OptimisticFIFOQueue-DISC2004.pdf">An Optimistic Approach to Lock Free FIFO Queues</a></p>

<h3 id="hash-map">Hash Map</h3>

<p><a href="http://www.win.tue.nl/~jfg/articles/CS-Report03-03.pdf">Efficient Almost Wait Free Parallel Accessible Dynamic Hash-tables</a></p>

<p><a href="http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-639.pdf">Non-Blocking Hash-Tables With Open Addressing</a></p>

<p><a href="http://cs.brown.edu/~mph/HellerHLMSS05/2005-OPODIS-Lazy.pdf">A Lazy Concurrent List-Based Set Algorithm</a></p>

<p><a href="http://www.research.ibm.com/people/m/michael/spaa-2002.pdf">High Performance Dynamic Lock-Free Hash Tables and List-Based Sets</a></p>

<h3 id="cuckoo-hash-map">Cuckoo Hash Map</h3>

<p><a href="http://excess-project.eu/publications/published/CuckooHashing_ICDCS.pdf">Lock-free Cuckoo Hashing</a></p>

<h3 id="b-tree">B+ Tree</h3>

<p><a href="http://www.cs.technion.ac.il/~erez/Papers/lfbtree-full.pdf">A Lock-Free B+ Tree</a></p>

<p><a href="http://www.cs.technion.ac.il/~anastas/lfbtree-spaa.pdf">A Lock-Free B+ Tree</a></p>

<h3 id="others">Others</h3>

<p><a href="https://www.research.ibm.com/people/m/michael/ieeetpds-2004.pdf">Hazard Pointers: Safe Memory Reclamation For Lock-Free Objects</a></p>

<p><a href="http://www.grame.fr/ressources/publications/fober-JIM2002.pdf">Lock Free Techniques for Concurrent Access to Shared Objects</a></p>

<p><a href="http://www.cs.rochester.edu/~scott/papers/1998_JPDC_nonblocking.pdf">Non-Blocking Algorithms and Preemption-Safe Locking on Multiprogrammed Shared Memory Multiprocessors</a></p>

<p><a href="http://cs.brown.edu/people/mph/HerlihyLM03/main.pdf">Obstruction-Free Synchronization: Double-Ended Queues as an Example</a></p>

<p><a href="http://www.research.ibm.com/people/m/michael/podc-2002.pdf">Safe Memory Reclamation for Dynamic Lock Free Objects Using Atomic Reads and Writes</a></p>

<p><a href="http://www.ece.uc.edu/~paw/classes/ece975/sp2010/papers/herlihy-05.pdf">Non-blocking Memory Management Support for Dynamic-Sized Data Structures</a></p>

<p><a href="http://cs.brown.edu/~mph/DohertyHLM04/ft_gateway.cfm.pdf">Bringing Practical Lock Free Synchronization to 64Bit Applications</a></p>

<p><a href="https://www.research.ibm.com/people/m/michael/pldi-2004.pdf">Scalable Lock-Free Dynamic Memory Allocation</a></p>

<p><a href="http://research.microsoft.com/pubs/209106/paper.pdf">Are Lock-Free Concurrent Algorithms Practically Wait-Free</a></p>

<p><a href="http://www.cl.cam.ac.uk/~pes20/cpp/popl085ap-sewell.pdf">Mathematizing C++ Concurrency</a></p>

<h2 id="pages">Pages</h2>

<p><a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p>

<p><a href="http://jakob.engbloms.se/archives/65">Dekker’s Algorithm Does not Work, as Expected</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[多线程内存问题分析之mprotect方法]]></title>
    <link href="http://www.yebangyu.org/blog/2016/02/01/detectmemoryghostinmultithread/"/>
    <updated>2016-02-01T22:24:25+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/02/01/detectmemoryghostinmultithread</id>
    <content type="html"><![CDATA[<p>多线程中的内存问题，一直被认为是噩梦般的存在，几乎只有高手、大仙才能解决。除了大量的打log、gdb调试、code review以及依靠多年的经验和直觉之外，有没有一些分析的手段和工具呢？答案是肯定的。本文首先介绍其中的一种：mprotect大法。通过mprotect，保护特定的感兴趣的内存，当有线程改写该区域时，会产生一个中断，我们在中断处理函数中把调用栈等信息打印出来。这是大概的思路，不过其中的问题很多，我们慢慢道来。</p>

<!--more-->

<h2 id="section">原理</h2>

<h3 id="mprotect">mprotect函数</h3>

<p>mprotect函数的原型如下：</p>

<p>int mprotect(const void *addr, size_t len, int prot);</p>

<p>其中addr是待保护的内存首地址，必须按页对齐；len是待保护内存的大小，必须是页的整数倍，prot代表模式，可能的取值有PROT_READ（表示可读）、PROT_WRITE（可写）等。</p>

<p>不同体系结构和操作系统，一页的大小不尽相同。如何获得页大小呢？通过PAGE_SIZE宏或者getpagesize()系统调用即可。</p>

<h3 id="section-1">定制中断处理函数</h3>

<p>当线程试图对我们已保护（成只读）的内存进行篡改时，默认情况下程序会收到SIGSEGV错误而退出。能不能不退出并且把相应的调用栈打印出来分析？当然可以。通过如下代码注册你定制的中断处理函数即可：</p>

<pre><code>struct sigaction act;
act.sa_sigaction = your_handler;
sigemptyset(&amp;act.sa_mask);
act.sa_flags = SA_SIGINFO;
if(sigaction(SIGSEGV, &amp;act, NULL) == -1) {
  perror("Register hanlder failed");
  exit(EXIT_FAILURE);
}
</code></pre>

<p>这样，控制流就会到达你编写的your_handler函数上。而your_handler的函数原型是：</p>

<p>void your_handler(int sig, siginfo_t *si, void *unused)；</p>

<p>编写your_handler函数即可？是的，不过这里面有两个注意事项：</p>

<p>1，中断处理函数里不应该调用内存分配函数，否则可能会引起double fault。因此，不适合调用backtrace_symbols（内部会动态分配内存），而是通过backtrace_symbols_fd直接将调用栈信息直接刷到文件中。</p>

<p>2，中断处理函数中应该恢复被保护内存为可写，否则会引起死循环。（再次中断并进入咱们编写的函数）</p>

<h3 id="section-2">封装</h3>

<p>为了方便使用，我封装了一个类，供参考：
<code>c++
#include &lt;fcntl.h&gt;
#include &lt;signal.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdint.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/user.h&gt;
#include &lt;execinfo.h&gt;
class MemoryDetector
{
public:
  typedef void (*segv_handler) (int sig, siginfo_t *si, void *unused);
  static void init(const char *path)
  {
    register_handler(handler);
    fd_ = open(path, O_RDWR|O_CREAT, 777);
  }
  static int protect(void *p, int len)
  {
    address_ = reinterpret_cast&lt;uint64_t&gt;(p);
    len_ = len;
    uint64_t start_address = (address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ);
  }
  static int umprotect(void *p, int len)
  {
    uint64_t tmp_address_ = reinterpret_cast&lt;uint64_t&gt;(p);
    uint64_t start_address = (tmp_address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ | PROT_WRITE);
  }
  static int umprotect()
  {
    uint64_t start_address = (address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ | PROT_WRITE);
  }
  static void finish()
  {
    close(fd_);
  }
private:
  static void register_handler(segv_handler sh)
  {
    struct sigaction act;
    act.sa_sigaction = sh;
    sigemptyset(&amp;act.sa_mask);
    act.sa_flags = SA_SIGINFO;
    if(sigaction(SIGSEGV, &amp;act, NULL) == -1){
      perror("Register hanlder failed");
      exit(EXIT_FAILURE);
    }
  }
  static void handler(int sig, siginfo_t *si, void *unused)
  {
    uint64_t address = reinterpret_cast&lt;uint64_t&gt;(si-&gt;si_addr);
    if (address &gt;= address_ &amp;&amp; address &lt; address_ + len_) {
      umprotect(si-&gt;si_addr, PAGE_SIZE);
      my_backtrace();
    }
  }
  static void my_backtrace()
  {
    const int N = 100;
    void* array[100];
    size_t size = backtrace(array, N);
    backtrace_symbols_fd(array, size, fd_);
  }
  static uint64_t address_;
  static int len_;
  static int fd_;
};
</code></p>

<p>这个封装还存在一些问题，比如缺少错误处理，待保护内存必须在一页内等。读者诸君可以根据需要自行完善。</p>

<h2 id="section-3">实战</h2>

<p>来个例子,实战一下吧
<code>c++
#include "test.h" //就是上面封装的MemoryDetector类
#include &lt;thread&gt;
using namespace std;
uint64_t MemoryDetector::address_ = 0;
int MemoryDetector::len_ = 0;
int MemoryDetector::fd_ = 0;
///////////////////////////////////////
int *p = NULL;
void g()
{
  usleep(2000000);
  char *q = reinterpret_cast&lt;char *&gt;(p);
  *(q+2) = 111;//非法篡改！！！
}
void f()
{
  p = new int(1);
  MemoryDetector::protect(p, 4);
}
int main()
{
  const char *path = "result.tmp";//调用栈信息存放路径
  MemoryDetector::init(path);
  std::thread t1(f);
  std::thread t2(g);
  t1.join();
  t2.join();
  MemoryDetector::finish();
  return 0;
}
</code>
用如下方式编译链接以上程序：</p>

<pre><code>g++ -g -rdynamic -std=c++11 -pthread  test.cpp -o test
</code></pre>

<p>程序运行结束后，打开result.tmp文件，看到如下内容：</p>

<pre><code>./test(_ZN14MemoryDetector12my_backtraceEv+0x26)[0x405ce8]
./test(_ZN14MemoryDetector7handlerEiP7siginfoPv+0x60)[0x405cc0]
/lib64/libpthread.so.0[0x339a80f500]
./test(_Z1gv+0x25)[0x405909]
./test(_ZNSt6thread5_ImplIPFvvEE6_M_runEv+0x16)[0x406e2c]
/usr/lib64/libstdc++.so.6[0x3a6f6b6490]
/lib64/libpthread.so.0[0x339a807851]
/lib64/libc.so.6(clone+0x6d)[0x339a4e767d]
</code></pre>

<p>注意其中的第四行：./test(_Z1gv+0x25)[0x405909]。使用addr2line命令：</p>

<pre><code>addr2line -e test 0x405909
</code></pre>

<p>获得非法篡改的代码位置：</p>

<p>/home/yebangyu/test.cpp:13</p>

<p>真相大白了。</p>

<h2 id="section-4">感谢</h2>

<p>我最早知道这个方法，是从我主管<a href="http://weibo.com/yangzhifeng83">杨志丰</a>先生那儿以及他的<a href="http://blog.csdn.net/killmice/article/details/38443343">这篇</a>文章。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spinlock and mutex]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/24/spinlock-and-mutex/"/>
    <updated>2016-01-24T15:50:31+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/24/spinlock-and-mutex</id>
    <content type="html"><![CDATA[<p>Spinlock（自旋锁）和mutex作为两种互斥锁，在并行编程中都得到了广泛应用。那么，这两种锁有什么区别吗？</p>

<p>当一个线程对Spinlock加锁时，如果该锁被其他线程占用，那么该线程会通过一个loop不断地重试（ try again and again）；而使用mutex的线程没有得到锁时，会sleep。</p>

<p>因为，当临界区较短时，Spinlock因为没有上下文切换，可能性能更优；当临界区较长时，不断的spin将浪费大量的cpu资源。</p>

<!--more-->

<p>如何实现一个Spinlock呢？下面简单封装了一下，并在Ubuntu 14.04 32bit系统，X86体系结构，Intel I5双核处理器环境下，测试相应的性能：</p>

<p><code>c++
#include&lt;thread&gt;
using namespace std;
int counter = 0;
int lock = 0;
void spin_lock()
{
  while(__sync_lock_test_and_set(&amp;lock, 1));
}
void spin_unlock()
{
  __sync_lock_release(&amp;lock);
}
void f()
{
  for (int i = 0; i &lt;  10000000; i++) {
    spin_lock();
    counter = counter + 2;//tiny critical section
    spin_unlock();
  }
}
int main() 
{
  thread t1(f);
  thread t2(f);
  t1.join();
  t2.join();
  return 0;
}
</code></p>

<p>2个线程时，这个程序的运行时间为：</p>

<pre><code>real	0m1.082s
user	0m2.060s
sys	0m0.000s
</code></pre>

<p>4个线程时：</p>

<pre><code>real	0m5.701s
user	0m19.400s
sys	0m0.000s
</code></pre>

<p>如果改为std::mutex(lock和unlock成员函数)呢？对比一下：</p>

<p>2个线程：</p>

<pre><code>real	0m3.081s
user	0m2.796s
sys	0m3.344s
</code></pre>

<p>4个线程：</p>

<pre><code>real	0m5.860s
user	0m6.004s
sys	0m14.936s
</code></pre>

<p>不难发现，由于大量的上下文切换，使用mutex时，花在sys上的时间要远比使用Spinlock的要多。</p>

<h2 id="section">小结</h2>

<p>以下两种情况，应该考虑使用spinlock代替mutex：</p>

<p>1，每个processor上（只）运行一个线程。</p>

<p>2，线程平均等待（spin）时间少于两次上下文切换的开销。</p>

<p>当然，一切都离不开实际的测试和分析。</p>

<p>下次，我们将研究更多、更高效的spinlock实现。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concurrent and Parallel]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/17/concurrenyandparallism/"/>
    <updated>2016-01-17T09:49:00+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/17/concurrenyandparallism</id>
    <content type="html"><![CDATA[<p>什么是并发(<strong>Concurrency，Concurrent</strong>)，什么是并行(<strong>parallism，Parallel</strong>)？这两者有什么区别？本文收录一下我听过的、我见过的、我看过的一些人的看法。仅供参考：</p>

<h2 id="paul-butcher">Paul Butcher</h2>

<p><strong>Paul Butcher</strong>在他的《<strong>Seven Concurrency Models in Seven Weeks</strong>
》里开篇就谈到：</p>

<!--more-->

<p>An alternative way of thinking about this is that concurrency is an aspect of
the problem domain—your program needs to handle multiple simultaneous
(or near-simultaneous) events. Parallelism, by contrast, is an aspect of the
solution domain—you want to make your program faster by processing different
portions of the problem in parallel</p>

<p>也就是说，并发是<strong>问题域</strong>，并行是<strong>解决域</strong>。问题是并发的，解决方法是并行的。</p>

<h2 id="rob-pike">Rob Pike</h2>

<p><strong>Rob</strong>是<strong>Go</strong>语言之父，《<strong>The Unix Programming Environment</strong>》 和 《<strong>The Practice of Programming</strong>》（最近正在重读这本小册子）的作者。他有一个经典的解释：</p>

<p>Concurrency is about dealing with lots of things at once.</p>

<p>Parallelism is about doing lots of things at once.</p>

<p>嘿嘿，这个有点意思，不过只能意会了。</p>

<h2 id="paul-e-mckenney">Paul E. McKenney</h2>

<p>又是一个<strong>Paul</strong>。不过这个<strong>Paul</strong>大叔是<strong>IBM</strong>的研究人员，写了一本非常幽默并且有深度的书：《<strong>Is Parallel Programming Hard, And, If So, What Can You Do About It?</strong>》（最近一直在细读，并且做读书笔记，感兴趣的朋友可以参考我的相关<a href="http://www.yebangyu.org/blog/categories/bing-xing-bian-cheng/">博客</a>。） 在这本书（<strong>v2015.01.31a</strong>版本）的第<strong>319</strong>页，有一个附录，介绍 <strong>What is the Difference Between</strong>
“<strong>Concurrent</strong>” <strong>and</strong> “<strong>Parallel</strong>”?时说：</p>

<p>From a classic computing perspective, “concurrent” and
“parallel” are clearly synonyms. However, this has not
stopped many people from drawing distinctions between
the two</p>

<p>说明<strong>Paul</strong>大叔认为，其实这两者是一回事，有些人非得区分。好吧，那就区分吧。这些人是如何区分呢？有两个<strong>perspective</strong>：</p>

<p>The first perspective treats “parallel” as an abbreviation
for “data parallel,” and treats “concurrent” as pretty
much everything else</p>

<p>也就是说，<strong>concurrency</strong>有很强的<strong>interdependencies</strong>，它们之间可能要做各种通信，基于比如说<strong>locks</strong>啊，<strong>transactions</strong>啊，等等同步机制。相比，<strong>parallel</strong>中组件的相互依赖就很少。新浪微博网友 <a href="http://weibo.com/u/1085583241">@小恶魔提利昂</a>就持这种观点，他说：“并发任务处理的时候，会在并发处理时候可以交换信息，有CSP式的，也可以内存共享式的，但是在外部看到的效果是若干核或若干线程/协程同时对应这些并发任务。并行处理的话，同时处理的任务要做到上下文环境都是隔离的。”</p>

<p>Now, this second perspective can be thought of as making
the workload match the available scheduler, with parallel
workloads able to operate on a simple scheduler
and concurrent workloads requiring more sophisticated
schedulers.</p>

<p>恩，第二个角度就是需不需要复杂的<strong>scheduler</strong>。</p>

<p>但是<strong>Paul</strong>大叔说，这两个视角很可能是不可兼得或者说矛盾滴。此话怎讲？</p>

<p>考虑每个<strong>CPU</strong>一个线程的基于<strong>lock</strong>通信的程序。是<strong>Concurrency</strong>吗？从第一个角度讲，是的，用<strong>lock</strong>啊，各种同步各种通信啊。从第二个角度看，又不是。</p>

<p>以上就是<strong>Paul McKenney</strong>大致的观点。</p>

<h2 id="yebangyu">yebangyu</h2>

<p><strong>yebangyu</strong>是博主，<strong>yebangyu.org</strong>公司CEO兼站长兼董事长兼老板，苦逼屌丝底层搬砖码农。恩，就是我了。</p>

<p>个人观点：</p>

<p>1，首先，持<strong>Paul McKenney</strong>的观点，没必要区分这两个词。</p>

<p>2，<strong>Concurrency</strong>这个单词含有类“occur”的词根，表示发生，<strong>con</strong>代表共同、一起，指共同发生的意思。而<strong>parallel</strong>词根是<strong>para</strong>，表示相同的、类似、平行的、差不多的。因为，也可以认为问题是同时发生的，解决方法是平行处理。</p>

<p>3，写书在取书名的时候需要区分。如果你是讲<strong>MPI、Open MP</strong>这类技术，建议用并行或者说<strong>Parallel Computing</strong>。如果是讲<strong>lock free、multi-thread</strong>这些共享内存编程的，建议用<strong>Concurrency</strong>或者<strong>Concurrency Programming</strong>。</p>

<p>那么，<strong>Go</strong>语言这种<strong>CSP</strong>类型的<strong>Channel</strong>的呢？个人认为，都可以吧。</p>
]]></content>
  </entry>
  
</feed>
