<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 并行编程 | Yebangyu's Blog]]></title>
  <link href="http://www.yebangyu.org/blog/categories/bing-xing-bian-cheng/atom.xml" rel="self"/>
  <link href="http://www.yebangyu.org/"/>
  <updated>2016-02-17T22:10:47+08:00</updated>
  <id>http://www.yebangyu.org/</id>
  <author>
    <name><![CDATA[Yebangyu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Materials In Concurrency Programming]]></title>
    <link href="http://www.yebangyu.org/blog/2016/02/16/materials-in-concurrency-programming/"/>
    <updated>2016-02-16T23:36:28+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/02/16/materials-in-concurrency-programming</id>
    <content type="html"><![CDATA[<h2 id="prerequisite">Prerequisite</h2>

<p>对CPU、内存、CacheLine有一个很好的认识，对学习并发编程有很大的帮助。</p>

<p><a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">What Every Programmer Should Know About Memory</a></p>

<p><a href="http://www.amazon.com/Consistency-Coherence-Synthesis-Lectures-Architecture/dp/1608455645">A Primer on Memory Consistency and Cache Coherence</a></p>

<!--more-->

<h2 id="textbook">Textbook</h2>

<p><a href="https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a></p>

<p>Paul大叔的神作。</p>

<p>优点：</p>

<p>1，很全面，除了介绍lock的实现、RCU、Transaction Memory等等之外，还包括一些并发程序设计的其他知识，比如如何验证、如何调试等。</p>

<p>个人非常喜欢第14章和附录C，分别详细介绍了什么是memory barrier以及为什么需要memory barrier。强烈推荐！</p>

<p>2，很正派。这里面介绍的技术都非常通用，普遍适用，没有太多的黑科技。比如书中重点强调的partition，就是一种非常重要、非常scientific的思想。</p>

<p>3，很幽默。真的，很幽默。</p>

<p>缺点：因为正派，所以就没有介绍lock free这种很tricky的黑科技，算是不足吧。</p>

<p>个人喜爱程度：5颗星</p>

<p><a href="http://www.amazon.com/The-Multiprocessor-Programming-Revised-Reprint/dp/0123973376">The Art of Multiprocessor Programming</a></p>

<p>被很多人推崇。第一版有很多错误，作者随后推出了revised版本。</p>

<p>优点：市面上目前能见到的唯一一本包括大量lock free data structure实现的书籍。</p>

<p>缺点：</p>

<p>1，java语言实现。我固执认为应该用C或者C++</p>

<p>2，没有介绍RCU等重要内容</p>

<p>3，不详细。可能是我个人实力不行，感觉这本书讲的并不好，看完还是得看论文才懂。</p>

<p>个人喜爱程度：3颗星</p>

<p><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00499ED1V01Y201304CAC023">Shared Memory Synchronization</a></p>

<p>优点：</p>

<p>1，很新。2013年的书</p>

<p>2，选题不错。综合了上面两本</p>

<p>缺点：</p>

<p>1，鸡肋。初学者看了云里雾里，高手没必要看。</p>

<p>是作者实力不够吗？恐怕不是。作者Michael L. Scott是程序语言设计和并发编程的大拿。</p>

<p>是作者表述能力不行吗？恐怕不是。他写有一本非常著名和畅销的书籍：《Programming Language Pragmatics》（我没读过）</p>

<p>这本书偏综述＋lecture notes性质，估计和这套、这系列丛书的定位有关。</p>

<p>2，没有中文版，没有英文影印版，很难下到pdf。苦逼穷学生想阅读的话基本上只能去amazon.com购买原版</p>

<p>个人喜爱程度：1颗星</p>

<h2 id="blog">Blog</h2>

<p><a href="http://preshingcom/">Jeff Preshing’s Blog</a></p>

<p><a href="http://www.cliffc.org/blog/">Cliff Click’s Blog</a></p>

<p><a href="http://www.yebangyu.org">Yebangyu’s Blog</a></p>

<h2 id="paper">Paper</h2>

<h3 id="linked-list--skip-list">Linked List &amp; Skip List</h3>

<p><a href="https://timharris.uk/papers/2001-disc.pdf">A Pragmatic Implementation of Non-Blocking Linked-Lists</a></p>

<p><a href="http://www.cse.yorku.ca/~ruppert/papers/lfll.pdf">Lock Free Linked Lists and Skip Lists</a></p>

<p><a href="http://www.cse.yorku.ca/~ruppert/Mikhail.pdf">Lock Free Linked Lists and Skip Lists</a></p>

<p><a href="http://cs.ucf.edu/~dcm/Teaching/COT4810-Spring2011/Literature/SplitOrderedLists.pdf">Split-Ordered Lists: Lockfree Extensible Hash Tables</a></p>

<p><a href="http://cs.brown.edu/~mph/LevHLS06/OPODIS2006-BA.pdf">A Provably Correct Scalable Concurrent Skip List</a></p>

<h3 id="stack">Stack</h3>

<p><a href="http://www.cs.bgu.ac.il/~hendlerd/papers/scalable-stack.pdf">A Scalable Lock Free Stack Algorithm</a></p>

<h3 id="queue">Queue</h3>

<p><a href="http://www.non-blocking.com/download/SunT03_PQueue_TR.pdf">Fast and Lock Free Concurrent Priority Queues for Multi-Thread Systems</a></p>

<p><a href="http://people.csail.mit.edu/edya/publications/OptimisticFIFOQueue-DISC2004.pdf">An Optimistic Approach to Lock Free FIFO Queues</a></p>

<h3 id="hash-map">Hash Map</h3>

<p><a href="http://www.win.tue.nl/~jfg/articles/CS-Report03-03.pdf">Efficient Almost Wait Free Parallel Accessible Dynamic Hash-tables</a></p>

<p><a href="http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-639.pdf">Non-Blocking Hash-Tables With Open Addressing</a></p>

<p><a href="http://cs.brown.edu/~mph/HellerHLMSS05/2005-OPODIS-Lazy.pdf">A Lazy Concurrent List-Based Set Algorithm</a></p>

<p><a href="http://www.research.ibm.com/people/m/michael/spaa-2002.pdf">High Performance Dynamic Lock-Free Hash Tables and List-Based Sets</a></p>

<h3 id="cuckoo-hash-map">Cuckoo Hash Map</h3>

<p><a href="http://excess-project.eu/publications/published/CuckooHashing_ICDCS.pdf">Lock-free Cuckoo Hashing</a></p>

<h3 id="b-tree">B+ Tree</h3>

<p><a href="http://www.cs.technion.ac.il/~erez/Papers/lfbtree-full.pdf">A Lock-Free B+ Tree</a></p>

<p><a href="http://www.cs.technion.ac.il/~anastas/lfbtree-spaa.pdf">A Lock-Free B+ Tree</a></p>

<h3 id="others">Others</h3>

<p><a href="https://www.research.ibm.com/people/m/michael/ieeetpds-2004.pdf">Hazard Pointers: Safe Memory Reclamation For Lock-Free Objects</a></p>

<p><a href="http://www.grame.fr/ressources/publications/fober-JIM2002.pdf">Lock Free Techniques for Concurrent Access to Shared Objects</a></p>

<p><a href="http://www.cs.rochester.edu/~scott/papers/1998_JPDC_nonblocking.pdf">Non-Blocking Algorithms and Preemption-Safe Locking on Multiprogrammed Shared Memory Multiprocessors</a></p>

<p><a href="http://cs.brown.edu/people/mph/HerlihyLM03/main.pdf">Obstruction-Free Synchronization: Double-Ended Queues as an Example</a></p>

<p><a href="http://www.research.ibm.com/people/m/michael/podc-2002.pdf">Safe Memory Reclamation for Dynamic Lock Free Objects Using Atomic Reads and Writes</a></p>

<p><a href="http://www.ece.uc.edu/~paw/classes/ece975/sp2010/papers/herlihy-05.pdf">Non-blocking Memory Management Support for Dynamic-Sized Data Structures</a></p>

<p><a href="http://cs.brown.edu/~mph/DohertyHLM04/ft_gateway.cfm.pdf">Bringing Practical Lock Free Synchronization to 64Bit Applications</a></p>

<p><a href="https://www.research.ibm.com/people/m/michael/pldi-2004.pdf">Scalable Lock-Free Dynamic Memory Allocation</a></p>

<p><a href="http://research.microsoft.com/pubs/209106/paper.pdf">Are Lock-Free Concurrent Algorithms Practically Wait-Free</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[多线程内存问题分析之mprotect方法]]></title>
    <link href="http://www.yebangyu.org/blog/2016/02/01/detectmemoryghostinmultithread/"/>
    <updated>2016-02-01T22:24:25+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/02/01/detectmemoryghostinmultithread</id>
    <content type="html"><![CDATA[<p>多线程中的内存问题，一直被认为是噩梦般的存在，几乎只有高手、大仙才能解决。除了大量的打log、gdb调试、code review以及依靠多年的经验和直觉之外，有没有一些分析的手段和工具呢？答案是肯定的。本文首先介绍其中的一种：mprotect大法。通过mprotect，保护特定的感兴趣的内存，当有线程改写该区域时，会产生一个中断，我们在中断处理函数中把调用栈等信息打印出来。这是大概的思路，不过其中的问题很多，我们慢慢道来。</p>

<!--more-->

<h2 id="section">原理</h2>

<h3 id="mprotect">mprotect函数</h3>

<p>mprotect函数的原型如下：</p>

<p>int mprotect(const void *addr, size_t len, int prot);</p>

<p>其中addr是待保护的内存首地址，必须按页对齐；len是待保护内存的大小，必须是页的整数倍，prot代表模式，可能的取值有PROT_READ（表示可读）、PROT_WRITE（可写）等。</p>

<p>不同体系结构和操作系统，一页的大小不尽相同。如何获得页大小呢？通过PAGE_SIZE宏或者getpagesize()系统调用即可。</p>

<h3 id="section-1">定制中断处理函数</h3>

<p>当线程试图对我们已保护（成只读）的内存进行篡改时，默认情况下程序会收到SIGSEGV错误而退出。能不能不退出并且把相应的调用栈打印出来分析？当然可以。通过如下代码注册你定制的中断处理函数即可：</p>

<pre><code>struct sigaction act;
act.sa_sigaction = your_handler;
sigemptyset(&amp;act.sa_mask);
act.sa_flags = SA_SIGINFO;
if(sigaction(SIGSEGV, &amp;act, NULL) == -1) {
  perror("Register hanlder failed");
  exit(EXIT_FAILURE);
}
</code></pre>

<p>这样，控制流就会到达你编写的your_handler函数上。而your_handler的函数原型是：</p>

<p>void your_handler(int sig, siginfo_t *si, void *unused)；</p>

<p>编写your_handler函数即可？是的，不过这里面有两个注意事项：</p>

<p>1，中断处理函数里不应该调用内存分配函数，否则可能会引起double fault。因此，不适合调用backtrace_symbols（内部会动态分配内存），而是通过backtrace_symbols_fd直接将调用栈信息直接刷到文件中。</p>

<p>2，中断处理函数中应该恢复被保护内存为可写，否则会引起死循环。（再次中断并进入咱们编写的函数）</p>

<h3 id="section-2">封装</h3>

<p>为了方便使用，我封装了一个类，供参考：
<code>c++
#include &lt;fcntl.h&gt;
#include &lt;signal.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdint.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/user.h&gt;
#include &lt;execinfo.h&gt;
class MemoryDetector
{
public:
  typedef void (*segv_handler) (int sig, siginfo_t *si, void *unused);
  static void init(const char *path)
  {
    register_handler(handler);
    fd_ = open(path, O_RDWR|O_CREAT, 777);
  }
  static int protect(void *p, int len)
  {
    address_ = reinterpret_cast&lt;uint64_t&gt;(p);
    len_ = len;
    uint64_t start_address = (address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ);
  }
  static int umprotect(void *p, int len)
  {
    uint64_t tmp_address_ = reinterpret_cast&lt;uint64_t&gt;(p);
    uint64_t start_address = (tmp_address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ | PROT_WRITE);
  }
  static int umprotect()
  {
    uint64_t start_address = (address_ &gt;&gt; PAGE_SHIFT) &lt;&lt; PAGE_SHIFT;
    return mprotect(reinterpret_cast&lt;void *&gt;(start_address), PAGE_SIZE, PROT_READ | PROT_WRITE);
  }
  static void finish()
  {
    close(fd_);
  }
private:
  static void register_handler(segv_handler sh)
  {
    struct sigaction act;
    act.sa_sigaction = sh;
    sigemptyset(&amp;act.sa_mask);
    act.sa_flags = SA_SIGINFO;
    if(sigaction(SIGSEGV, &amp;act, NULL) == -1){
      perror("Register hanlder failed");
      exit(EXIT_FAILURE);
    }
  }
  static void handler(int sig, siginfo_t *si, void *unused)
  {
    uint64_t address = reinterpret_cast&lt;uint64_t&gt;(si-&gt;si_addr);
    if (address &gt;= address_ &amp;&amp; address &lt; address_ + len_) {
      umprotect(si-&gt;si_addr, PAGE_SIZE);
      my_backtrace();
    }
  }
  static void my_backtrace()
  {
    const int N = 100;
    void* array[100];
    size_t size = backtrace(array, N);
    backtrace_symbols_fd(array, size, fd_);
  }
  static uint64_t address_;
  static int len_;
  static int fd_;
};
</code></p>

<p>这个封装还存在一些问题，比如缺少错误处理，待保护内存必须在一页内等。读者诸君可以根据需要自行完善。</p>

<h2 id="section-3">实战</h2>

<p>来个例子,实战一下吧
<code>c++
#include "test.h" //就是上面封装的MemoryDetector类
#include &lt;thread&gt;
using namespace std;
uint64_t MemoryDetector::address_ = 0;
int MemoryDetector::len_ = 0;
int MemoryDetector::fd_ = 0;
///////////////////////////////////////
int *p = NULL;
void g()
{
  usleep(2000000);
  char *q = reinterpret_cast&lt;char *&gt;(p);
  *(q+2) = 111;//非法篡改！！！
}
void f()
{
  p = new int(1);
  MemoryDetector::protect(p, 4);
}
int main()
{
  const char *path = "result.tmp";//调用栈信息存放路径
  MemoryDetector::init(path);
  std::thread t1(f);
  std::thread t2(g);
  t1.join();
  t2.join();
  MemoryDetector::finish();
  return 0;
}
</code>
用如下方式编译链接以上程序：</p>

<pre><code>g++ -g -rdynamic -std=c++11 -pthread  test.cpp -o test
</code></pre>

<p>程序运行结束后，打开result.tmp文件，看到如下内容：</p>

<pre><code>./test(_ZN14MemoryDetector12my_backtraceEv+0x26)[0x405ce8]
./test(_ZN14MemoryDetector7handlerEiP7siginfoPv+0x60)[0x405cc0]
/lib64/libpthread.so.0[0x339a80f500]
./test(_Z1gv+0x25)[0x405909]
./test(_ZNSt6thread5_ImplIPFvvEE6_M_runEv+0x16)[0x406e2c]
/usr/lib64/libstdc++.so.6[0x3a6f6b6490]
/lib64/libpthread.so.0[0x339a807851]
/lib64/libc.so.6(clone+0x6d)[0x339a4e767d]
</code></pre>

<p>注意其中的第四行：./test(_Z1gv+0x25)[0x405909]。使用addr2line命令：</p>

<pre><code>addr2line -e test 0x405909
</code></pre>

<p>获得非法篡改的代码位置：</p>

<p>/home/yebangyu/test.cpp:13</p>

<p>真相大白了。</p>

<h2 id="section-4">感谢</h2>

<p>我最早知道这个方法，是从我主管<a href="http://weibo.com/yangzhifeng83">杨志丰</a>先生那儿以及他的<a href="http://blog.csdn.net/killmice/article/details/38443343">这篇</a>文章。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spinlock and mutex]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/24/spinlock-and-mutex/"/>
    <updated>2016-01-24T15:50:31+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/24/spinlock-and-mutex</id>
    <content type="html"><![CDATA[<p>Spinlock（自旋锁）和mutex作为两种互斥锁，在并行编程中都得到了广泛应用。那么，这两种锁有什么区别吗？</p>

<p>当一个线程对Spinlock加锁时，如果该锁被其他线程占用，那么该线程会通过一个loop不断地重试（ try again and again）；而使用mutex的线程没有得到锁时，会sleep。</p>

<p>因为，当临界区较短时，Spinlock因为没有上下文切换，可能性能更优；当临界区较长时，不断的spin将浪费大量的cpu资源。</p>

<!--more-->

<p>如何实现一个Spinlock呢？下面简单封装了一下，并在Ubuntu 14.04 32bit系统，X86体系结构，Intel I5双核处理器环境下，测试相应的性能：</p>

<p><code>c++
#include&lt;thread&gt;
using namespace std;
int counter = 0;
int lock = 0;
void spin_lock()
{
  while(__sync_lock_test_and_set(&amp;lock, 1));
}
void spin_unlock()
{
  __sync_lock_release(&amp;lock);
}
void f()
{
  for (int i = 0; i &lt;  10000000; i++) {
    spin_lock();
    counter = counter + 2;//tiny critical section
    spin_unlock();
  }
}
int main() 
{
  thread t1(f);
  thread t2(f);
  t1.join();
  t2.join();
  return 0;
}
</code></p>

<p>2个线程时，这个程序的运行时间为：</p>

<pre><code>real	0m1.082s
user	0m2.060s
sys	0m0.000s
</code></pre>

<p>4个线程时：</p>

<pre><code>real	0m5.701s
user	0m19.400s
sys	0m0.000s
</code></pre>

<p>如果改为std::mutex(lock和unlock成员函数)呢？对比一下：</p>

<p>2个线程：</p>

<pre><code>real	0m3.081s
user	0m2.796s
sys	0m3.344s
</code></pre>

<p>4个线程：</p>

<pre><code>real	0m5.860s
user	0m6.004s
sys	0m14.936s
</code></pre>

<p>不难发现，由于大量的上下文切换，使用mutex时，花在sys上的时间要远比使用Spinlock的要多。</p>

<h2 id="section">小结</h2>

<p>以下两种情况，应该考虑使用spinlock代替mutex：</p>

<p>1，每个processor上（只）运行一个线程。</p>

<p>2，线程平均等待（spin）时间少于两次上下文切换的开销。</p>

<p>当然，一切都离不开实际的测试和分析。</p>

<p>下次，我们将研究更多、更高效的spinlock实现。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concurrent and Parallel]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/17/concurrenyandparallism/"/>
    <updated>2016-01-17T09:49:00+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/17/concurrenyandparallism</id>
    <content type="html"><![CDATA[<p>什么是并发(<strong>Concurrency，Concurrent</strong>)，什么是并行(<strong>parallism，Parallel</strong>)？这两者有什么区别？本文收录一下我听过的、我见过的、我看过的一些人的看法。仅供参考：</p>

<h2 id="paul-butcher">Paul Butcher</h2>

<p><strong>Paul Butcher</strong>在他的《<strong>Seven Concurrency Models in Seven Weeks</strong>
》里开篇就谈到：</p>

<!--more-->

<p>An alternative way of thinking about this is that concurrency is an aspect of
the problem domain—your program needs to handle multiple simultaneous
(or near-simultaneous) events. Parallelism, by contrast, is an aspect of the
solution domain—you want to make your program faster by processing different
portions of the problem in parallel</p>

<p>也就是说，并发是<strong>问题域</strong>，并行是<strong>解决域</strong>。问题是并发的，解决方法是并行的。</p>

<h2 id="rob-pike">Rob Pike</h2>

<p><strong>Rob</strong>是<strong>Go</strong>语言之父，《<strong>The Unix Programming Environment</strong>》 和 《<strong>The Practice of Programming</strong>》（最近正在重读这本小册子）的作者。他有一个经典的解释：</p>

<p>Concurrency is about dealing with lots of things at once.</p>

<p>Parallelism is about doing lots of things at once.</p>

<p>嘿嘿，这个有点意思，不过只能意会了。</p>

<h2 id="paul-e-mckenney">Paul E. McKenney</h2>

<p>又是一个<strong>Paul</strong>。不过这个<strong>Paul</strong>大叔是<strong>IBM</strong>的研究人员，写了一本非常幽默并且有深度的书：《<strong>Is Parallel Programming Hard, And, If So, What Can You Do About It?</strong>》（最近一直在细读，并且做读书笔记，感兴趣的朋友可以参考我的相关<a href="http://www.yebangyu.org/blog/categories/bing-xing-bian-cheng/">博客</a>。） 在这本书（<strong>v2015.01.31a</strong>版本）的第<strong>319</strong>页，有一个附录，介绍 <strong>What is the Difference Between</strong>
“<strong>Concurrent</strong>” <strong>and</strong> “<strong>Parallel</strong>”?时说：</p>

<p>From a classic computing perspective, “concurrent” and
“parallel” are clearly synonyms. However, this has not
stopped many people from drawing distinctions between
the two</p>

<p>说明<strong>Paul</strong>大叔认为，其实这两者是一回事，有些人非得区分。好吧，那就区分吧。这些人是如何区分呢？有两个<strong>perspective</strong>：</p>

<p>The first perspective treats “parallel” as an abbreviation
for “data parallel,” and treats “concurrent” as pretty
much everything else</p>

<p>也就是说，<strong>concurrency</strong>有很强的<strong>interdependencies</strong>，它们之间可能要做各种通信，基于比如说<strong>locks</strong>啊，<strong>transactions</strong>啊，等等同步机制。相比，<strong>parallel</strong>中组件的相互依赖就很少。新浪微博网友 <a href="http://weibo.com/u/1085583241">@小恶魔提利昂</a>就持这种观点，他说：“并发任务处理的时候，会在并发处理时候可以交换信息，有CSP式的，也可以内存共享式的，但是在外部看到的效果是若干核或若干线程/协程同时对应这些并发任务。并行处理的话，同时处理的任务要做到上下文环境都是隔离的。”</p>

<p>Now, this second perspective can be thought of as making
the workload match the available scheduler, with parallel
workloads able to operate on a simple scheduler
and concurrent workloads requiring more sophisticated
schedulers.</p>

<p>恩，第二个角度就是需不需要复杂的<strong>scheduler</strong>。</p>

<p>但是<strong>Paul</strong>大叔说，这两个视角很可能是不可兼得或者说矛盾滴。此话怎讲？</p>

<p>考虑每个<strong>CPU</strong>一个线程的基于<strong>lock</strong>通信的程序。是<strong>Concurrency</strong>吗？从第一个角度讲，是的，用<strong>lock</strong>啊，各种同步各种通信啊。从第二个角度看，又不是。</p>

<p>以上就是<strong>Paul McKenney</strong>大致的观点。</p>

<h2 id="yebangyu">yebangyu</h2>

<p><strong>yebangyu</strong>是博主，<strong>yebangyu.org</strong>公司CEO兼站长兼董事长兼老板，苦逼屌丝底层搬砖码农。恩，就是我了。</p>

<p>个人观点：</p>

<p>1，首先，持<strong>Paul McKenney</strong>的观点，没必要区分这两个词。</p>

<p>2，<strong>Concurrency</strong>这个单词含有类“occur”的词根，表示发生，<strong>con</strong>代表共同、一起，指共同发生的意思。而<strong>parallel</strong>词根是<strong>para</strong>，表示相同的、类似、平行的、差不多的。因为，也可以认为问题是同时发生的，解决方法是平行处理。</p>

<p>3，写书在取书名的时候需要区分。如果你是讲<strong>MPI、Open MP</strong>这类技术，建议用并行或者说<strong>Parallel Computing</strong>。如果是讲<strong>lock free、multi-thread</strong>这些共享内存编程的，建议用<strong>Concurrency</strong>或者<strong>Concurrency Programming</strong>。</p>

<p>那么，<strong>Go</strong>语言这种<strong>CSP</strong>类型的<strong>Channel</strong>的呢？个人认为，都可以吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Memory Consistency和Cache Coherence]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/09/memoryconsistencyandcachecoherence/"/>
    <updated>2016-01-09T22:52:52+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/09/memoryconsistencyandcachecoherence</id>
    <content type="html"><![CDATA[<h2 id="memory-consistency">Memory Consistency</h2>

<p><strong>Memory Consistency</strong>(<strong>MC</strong>)，有时候又叫做<strong>Memory Consistency Model</strong>或者<strong>Memory Model</strong>。为了理解为什么需要引入这种东西，我们首先看以下程序：</p>

<!--more-->

<pre><code>初始：x=0 y=0

Thread1：

S1：x=1

L1：r1=y

Thread2：

S2：y=2

L2：r2=x
</code></pre>

<p>其中，<strong>S1、S2、L1、L2</strong>是语句代号（<strong>BTW</strong>，<strong>S</strong>表示<strong>Store</strong>，<strong>L</strong>表示<strong>Load</strong>）；<strong>r1</strong>和<strong>r2</strong>是两个寄存器。<strong>x</strong>和<strong>y</strong>是两个不同的内存变量。</p>

<p>两个线程执行完之后，<strong>r1</strong>和<strong>r2</strong>可能是什么值？</p>

<p>注意到线程是并发、交替执行的，下面是可能的执行顺序和相应结果：</p>

<p><strong>S1 L1 S2 L2</strong> 那么<strong>r1=0 r2=2</strong></p>

<p><strong>S1 S2 L1 L2</strong> 那么<strong>r1=2 r2=1</strong></p>

<p><strong>S2 L2 S1 L1</strong> 那么<strong>r1=2 r2=0</strong></p>

<p>这些都是意料之内、情理之中的。但是在<strong>x86</strong>体系结构下，很可能得到<strong>r1=0 r2=0</strong>这样的结果。是不是大吃一惊？</p>

<p>如果没有<strong>Memory Consistency</strong>，那么程序员对于自己编写的多线程程序会输出什么将一无所知：天知道会输出什么。</p>

<p>因此，<strong>Memory Consistency</strong>就是程序员（编程语言）、编译器、CPU间的一种协议。这个协议保证了程序访问内存时可能得到什么值，会得到什么值。</p>

<h2 id="sequential-consistency">Sequential Consistency</h2>

<p>在<strong>Sequential Consistency</strong>这种<strong>Memory Model</strong>下，刚才讨论的那个程序不可能输出<strong>r1=0 r2=0</strong>这种结果。怎么说？这就牵涉到一个问题：什么是<strong>Sequential Consistency</strong>（<strong>SC</strong>）。</p>

<p>根据<strong>Leslie Lamport</strong>在<strong>1979</strong>年<strong>9</strong>月发表的论文《<strong>How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs</strong>》里提出的<strong>SC</strong>的定义：</p>

<p>the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.</p>

<p>根据这个定义，在<strong>SC</strong>模型下，任何<strong>execution</strong>的执行顺序（我们称为<strong>Memory Order</strong>）必须<strong>respect</strong>每个线程的<strong>Program Order</strong>。什么是<strong>Program Order</strong>？对于以上程序，在<strong>Thread1</strong>中，<strong>S1</strong>先于<strong>L1</strong>（不妨记为<strong>S1&lt;L1</strong>）；在<strong>Thread2</strong>中，<strong>S2</strong>先于<strong>L2</strong>（记为<strong>S2&lt;L2</strong>）。这就是<strong>Program Order</strong>。</p>

<p>请时刻注意，<strong>Program Order</strong>只针对某个线程内的语句而言，不涉及到跨线程。比如<strong>Thread1</strong>中的<strong>S1</strong>和<strong>Thread2</strong>中的<strong>L2</strong>，就无所谓什么<strong>Program Order</strong>了。</p>

<p>好了，现在知道为什么在<strong>SC</strong>下，有些结果可能出现，有些不可能了。</p>

<p><strong>S1 L1 S2 L2 r1=0 r2=2</strong> 没问题，没有违背<strong>S1&lt;L1 S2&lt;L2</strong></p>

<p><strong>S1 S2 L1 L2 r1=1 r2=2</strong> 没问题，没有违背<strong>S1&lt;L1 S2&lt;L2</strong></p>

<p><strong>S2 L2 S1 L1 r1=2 r2=0</strong> 没问题，没有违背<strong>S1&lt;L1 S2&lt;L2</strong></p>

<p>而对于<strong>r1=0 r2=0</strong>，在<strong>SC</strong>下，我们找不到一个能<strong>respect Program Order</strong>的<strong>Memory Order</strong>。因为<strong>r1=0</strong>，说明<strong>L1&lt;S2</strong>，<strong>r2=0</strong>说明<strong>L2&lt;S1</strong>；而<strong>S1&lt;L1，S2&lt;L2</strong>，不难看出这里形成了一个环。</p>

<h2 id="cache-coherence">Cache Coherence</h2>

<p>还是先搬出这张图吧:</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/cpuand%20cache.png" alt="memorycache" /></p>

<p>(图片来源于<strong>Paul</strong>大叔的《<strong>Is Parallel Programming Hard</strong>》这本书第三章)</p>

<p>多个<strong>CPU cores</strong>，每个<strong>core</strong>上有自己的<strong>Cache</strong>。我们知道，<strong>Cache</strong>是部分内存的映射和缓存，或者说，副本。这就带来一个问题：副本一致性。内存只有一个，每个<strong>cpu cores</strong>却有自己的内存副本，如何保证大家看到的内容是一样的、一致的、正确的呢？这就是<strong>Cache Coherence(CC)</strong>要解决的问题。</p>

<h2 id="cache-coherence--vs-memory-consistency">Cache Coherence  VS Memory Consistency</h2>

<p>从以上分析，我们不难看出，<strong>CC</strong>和<strong>MC</strong>涉及的是两个不同层面的东西，解决的是不同的问题，不可混淆。<strong>CC</strong>解决的是副本一致性问题；<strong>MC</strong>保证的是多线程程序访问内存时可以（可能）读到什么值。</p>

<p>两者有联系吗？有。实现<strong>Memory Consistency</strong>时可能会使用到<strong>Cache Coherence</strong>。细节下次我们接着聊。</p>

<h2 id="section">附录</h2>

<p>1，在并行编程中，我们常常有一个问题，或者需求：比如说上面的那个程序，如何保证线程<strong>2</strong>读到的<strong>x</strong>是线程<strong>1</strong>更新（<strong>x=1</strong>）后的<strong>x</strong>的值呢？</p>

<p>如果不加任何同步设施，仅仅考虑上面的程序，那么答案是：无法保证。因为线程的推进速度不同，哪条指令先被执行也一无所知。这个程序重跑几次，也可能输出不同的结果出来。</p>

<p>也就是说，<strong>Memory Model</strong>保证的是，例如，当线程<strong>2</strong>看到<strong>x</strong>等于<strong>1</strong>的时候，线程<strong>1</strong>是否已经执行了<strong>L1</strong>。也就是说，<strong>Memory Model</strong>确保当一件事情发生时，有其他什么事情<strong>has happened</strong>。在<strong>SC</strong>中，当<strong>L1</strong>发生时，说明或者说暗示着，<strong>S1</strong>已经发生了。</p>

<p>2，为什么<strong>x86</strong>下可能得出<strong>r1=0 r2=0</strong>的结果？</p>

<p>因为<strong>S1</strong>是写一个内存变量而<strong>L1</strong>是读取另一个内存变量（两个变量，或者说两个内存地址），这种情况下的写读可能被<strong>CPU</strong>乱序：先执行<strong>L1</strong>，再执行<strong>S1</strong>。（为了性能，所谓的延后写）</p>

<h2 id="section-1">致谢</h2>

<p>本文发出后，微博网友@linyvxiang 指出了其中的一个笔误，非常感谢。</p>
]]></content>
  </entry>
  
</feed>
