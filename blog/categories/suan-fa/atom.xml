<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 算法 | Yebangyu's Blog]]></title>
  <link href="http://www.yebangyu.org/blog/categories/suan-fa/atom.xml" rel="self"/>
  <link href="http://www.yebangyu.org/"/>
  <updated>2016-01-30T14:26:23+08:00</updated>
  <id>http://www.yebangyu.org/</id>
  <author>
    <name><![CDATA[Yebangyu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[深入解析Bloom Filter(中)]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/29/insidethebloomfilter/"/>
    <updated>2016-01-29T22:38:31+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/29/insidethebloomfilter</id>
    <content type="html"><![CDATA[<p>本篇将介绍：</p>

<blockquote>
  <ul>
    <li>d-left hashing</li>
    <li>d-left counting bloom filter</li>
  </ul>
</blockquote>

<p>在<a href="http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter/">上篇</a>文章，我们介绍了Standard Bloom Filter(SBF)和Counting Bloom Filter(CBF)。简单回顾下，我们大概思路和历程是：为了解决允许false positive下的membership问题，我们设计了哈希表算法，由于它所需空间巨大，我们引入bitmap方法；因为它false positive possibility太大，我们引入了SBF，它使用多个独立的、均匀分布的哈希函数。而SBF的一个缺点是不支持删除操作，为了能够删除，我们引入了CBF，然而，CBF存在一个问题。</p>

<p>什么问题呢？那就是空间利用率不高。这可以通过简单的数学计算知道大概：</p>

<p>考察某个位置，该位置的计数器counter的值$\xi$</p>

<p>$P(\xi = c) \approx \binom{mk}{c} {(\frac{1}{n})}^{c}({1-\frac{1}{n}})^{mk-c} = B(km,\frac{1}{n})$</p>

<p>若二项分布B(n,p)里n很大，p很小时，二项分布的极限近似分布是泊松分布$P(\lambda=k) = \frac{\lambda^k}{k!}{e}^{-\lambda}$，其中$\lambda=np=\frac{km}{n}$，并结合$k = \frac{n}{m}ln2$，可以得到，counter的期望值为：</p>

<p>$E(\xi) = \lambda = np = ln2 \approx 0.7$</p>

<p>即大量的counter的值都是0，空间效率不高。</p>

<p>在介绍新的Bloom Filter之前，我们一起先看看什么是所谓的d-left hashing。</p>

<h3 id="d-left-hashing">d-left hashing</h3>

<p>在d-left hashing中，我们有d张哈希子表（序号分别为1,2,…d，并且假设是从左到右），每张子表都包含B个bucket，每个bucket都包含w个cell，每个cell可以存放一个元素。</p>

<p>为了插入一个元素x，我们：</p>

<p>1，首先通过一个哈希函数hf，得到x的哈希函数值value = hf(x)</p>

<p>2，通过value，得到d个位置（每个位置对应每张子表），表示为：</p>

<p>(1,$B_1$) , (2,$B_2$),… (d,$B_d$)</p>

<p>其中(i,$B_i$)表示第i张子表，Bucket的index为$B_i$。</p>

<p>那么，到底插入哪张表呢？d-left hashing选择$B_i$中负载最小（已经存放的元素最少）的位置。注意，这里说的是bucket的负载，不是子表的负载。如果有多个子表对应的位置负载都是最小，那么选择最左边（序号最小）的子表插入。</p>

<p>为了查找该元素，我们需要检查d个位置，wd个cell（元素）。</p>

<h3 id="d-left-counting-bloom-filter">d-left counting bloom filter</h3>

<p>在基于d-left hashing的CBF中，我们有d张哈希子表（序号分别为1,2,…d，并且假设是从左到右），每张子表都包含B个bucket，每个bucket都包含w个cell，每个cell可以存放一个counter和一个fingerprint。</p>

<p>为了插入一个元素x，我们：</p>

<p>1，首先通过一个哈希函数hf，得到x的哈希函数值value = hf(x)</p>

<p>2，通过value，得到d个位置（每个位置对应每张子表）和对应的fingerprint，表示为d个位置向量：</p>

<p>(1,$B_1$,$fp_1$) , (2,$B_2$,$fp_2$),… (d,$B_d$,$fp_d$)</p>

<p>其中位置向量(i,$B_i$,$fp_i$)表示第i张子表，Bucket的index为$B_i$，fingerprint为$fp_i$。</p>

<p>3，通过d-left hashing将x插入，如果插入的位置(i,$B_i$,$fp_i$)上已经有cell的fingerprint等于$fp_i$，那么只需要将它的counter++即可。</p>

<p>举个栗子，假设某时刻，我们有：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/dleftcbf1.jpg" alt="d-leftcbf1" /></p>

<p>2张子表（d=2），每张子表有6个bucket（B=6），每个bucket包括3个cell（w=3），每个cell可以存放一个counter(4位表示，最大值为16)和fingerprint（6位表示）。</p>

<p>假如我们要插入元素x，我们对它进行hash，得到两个位置向量：</p>

<p>(1, 1, 010100)和(2, 2, 010101)</p>

<p>$d_1$子表中index为1的bucket的负载，要小于$d_2$子表中index为2的bucket的负载，因此，我们选择插入$d_1$中，如下：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/dleftcbf2.jpg" alt="d-leftcbf2" /></p>

<p>如果得到的位置向量分别是(1, 1, 001100)和(2, 2, 010101)呢？那么，还是插入到$d_1$中index为1的bucket中，但是只需要将第二个cell里的counter++即可，如下图：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/dleftcbf3.jpg" alt="d-leftcbf3" /></p>

<p>看起来很完美，但是这种方案在删除时会有问题。比如说，还是刚才的例子，我们欲插入x和y。分别得到x和y的位置向量们：</p>

<p>x: (1, 1, 010100)和(2, 2, 010101)</p>

<p>y: (1, 1, 010100)和(2, 4, 111111)</p>

<p>根据d-left hashing，x被插入到$d_1$中index为1的bucket中；y被插入到$d_2$中index为4的bucket中。好，这没问题。如果现在要删除y呢？我们需要检查两个位置，$d_1$中的index为1的bucket，以及$d_2$中index为4的bucket，要删哪个？fp都是010100啊。这就出现问题。</p>

<p>什么时候会出现这种问题？当以下条件满足时：</p>

<p>1，两个元素的有公共【重合】的位置向量。位置向量相同，表示同一个子表，同一个bucket，以及相同的fingerprint。</p>

<p>2，其中一个元素被插入了公共位置向量对应的位置，另外一个元素没有。</p>

<p>3，欲删除未使用公共位置向量的元素（比如说上例中的y）</p>

<p>为了解决这个问题，作者做了两点改进：</p>

<p>I 引入d轮随机置换。</p>

<p>置换，即一一映射。假设置换为P，输入为x和y，那么将满足：</p>

<p>如果a = b，那么P(a) = P(b)</p>

<p>如果a != b ，那么P(a) != P(b)</p>

<p>以及它们的逆否命题</p>

<p>如果P(a) ！= P(b)，那么a ！= b</p>

<p>如果P(a) = P(b)，那么a = b</p>

<p>为了插入x，我们首先通过一个哈希函数hf，计算它的哈希函数值value = hf(x)。然后，我们对value进行d轮随机置换，得到d个位置向量：</p>

<p>$P_1(value) = (1, B_1, fp_1)$</p>

<p>$P_2(value) = (2, B_2, fp_2)$</p>

<p>……</p>

<p>$P_d(value) = (d, B_d, fp_d)$</p>

<p>这里面有一个小问题：如果要插入的元素x和y不等，那么它们的置换可能相等吗？当然可能。因为x和y虽然不等，但是它们的hash value可能相等，这样它们的置换结果即位置向量可能相同。</p>

<p>别忘了，我们是对x和y的hash value进行置换，不是对x和y进行置换。</p>

<p>网上流传很广的<a href="http://blog.csdn.net/jiaomeng/article/details/1526099">这篇</a>文章的解释是错误的，小心！！！</p>

<p>II 插入修正</p>

<p>当得到d个位置向量后，和上面介绍的过程稍微不同：我们首先需要根据d个位置向量，从第1个子表开始，对每个子表$d_i$，去对应的位置$B_i$处查找是否有cell中的fp等于$fp_i$，如果有，我们把相应的counter++，插入动作完成，不用再继续检查后续子表了。</p>

<p>否则，当所有d个子表都没有对应的$fp_i$时，我们运用d-left hashing，插入x。</p>

<p>综合运用这两点，我们知道上面所说的删除时的问题已经不存在了。假如对x和y进行d轮（这里d=2）随机置换，得到它们的位置向量：</p>

<p>x: (1, 1, 010100)和(2, 2, 010101)</p>

<p>y: (1, 1, 010100)和(2, 4, 010101)</p>

<p>插入y的时候，需要先检查$d_1$中index为1的bucket中是否有fp = 010100，发现有（为嘛有？插入x的时候存储的），我们更新相应的counter，插入y宣告完成。</p>

<p>而且，我们发现，x和y的第一个位置向量（对应第一张子表）完全相同（bucket index相同，fp也相同），也就是</p>

<p>$P_1(hf(x)) = P_1(hf(y))$</p>

<p>那么可以推出hf(x) = hf(y)，也就是x和y的哈希函数值相等。</p>

<h2 id="section">附录</h2>

<h3 id="section-1">随机置换是必需的吗？</h3>

<p>插入修正和随机置换是作者引入用来解决删除时的歧义问题。我们的思考是：为了解决删除问题，随机置换是否必需？换句话说，插入修正是否足矣？</p>

<p>个人认为，插入修正足矣。那么作者为什么要引入随机置换呢？原因在于，引入随机置换后，置换后的结果即位置向量和哈希函数值有了因果关系，提供了一种保证：只有哈希函数值相等，才可能产生相同的随机置换结果，也就是产生公共的位置向量，这降低了产生false positive的可能性。</p>

<h3 id="section-2">如何随机置换</h3>

<p>作者提供了一个简单的函数：</p>

<p>$P_i(value) = (a * value ) mod 2^B$</p>

<p>其中value的范围是[0, $2^B$]，a是随机的一个奇数。</p>

<h3 id="section-3">数学分析</h3>

<p>首先，如果z是false positive，那么它的哈希函数值会和集合S中的某个元素的哈希函数值相等。也就是</p>

<p>hf(z) = hf(e) 其中 $e\in S$</p>

<p>这是因为，如果z是false positive，那么</p>

<p>$p_i(hf(z)) = p_i(hf(e))$</p>

<p>根据置换的性质，可得hf(z) = hf(e)</p>

<p>因此，false positive possibility为</p>

<p>$P = 1 - (1 - \frac{1}{B}*\frac{1}{2^r})^m$</p>

<p>根据伯努利公式，当x很小时，$(1+x)^a \approx 1 + ax$，所以</p>

<p>$P \approx 1 - (1 - m * \frac{1}{B} * \frac{1}{2^r}) \approx \frac{m}{B*2^r}$</p>

<p>那么d-left CBF的false positive和空间利用情况如何？我们下面简单分析一下：</p>

<p>比较嘛，肯定是相同的空间利用，比较谁的false positive possibility小；相同的false positive possibility下，谁所需空间少。</p>

<p>在CBF中，假设counter需要c位（上次我们分析过，c取4足矣），那么所需的空间是cn。结合$k = \frac{n}{m}ln2$，false positive possibility大约为$(0.6185)^{\frac{n}{m}}$。</p>

<p>在d-left CBF中，我们选择d=4，B=$\frac{m}{24}$，w=8（平均负载为6，这样$4 * \frac{m}{24} * 6 = m$），counter占用2位，fingerprint占用r位。那么它的空间占用为</p>

<p>$4 * \frac{m}{24} * 8  * (2+r) = \frac{4m(r+2)}{3}$</p>

<p>而false positive possibility的大概为 $\frac{m}{B<em>2^r} = 24</em>\frac{1}{2^r}$（别忘了，B=$\frac{m}{24}$）</p>

<p>通过计算不难发现，当空间占用相等时，d-left CBF的false positive possibility是CBF的百分之一；当false positive possibility相等时，d-left CBF所需空间是CBF的一半。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入解析Bloom Filter(上)]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter/"/>
    <updated>2016-01-23T13:24:49+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter</id>
    <content type="html"><![CDATA[<p>本文将介绍：</p>

<blockquote>
  <ul>
    <li>Bloom Filter和它的变形与拓展</li>
    <li>Bloom Filter的使用场景</li>
    <li>Bloom Filter的详细数学分析</li>
  </ul>
</blockquote>

<h2 id="section">提出问题</h2>

<p>Google的爬虫每天需要抓取大量的网页。于是就有一个问题：每当爬虫分析出一个url的时候，是抓呢，还是不抓呢？如何知道这个url已经爬过了？</p>

<!--more-->

<p>这个问题，归纳抽象后可以定义为：</p>

<p>给定一个集合S（注意，这里的集合是传统意义上的集合：元素彼此不同。本文不考虑multiset），给定一个元素e，需要判断$e\in S$ 是否成立。（学术界一般称为membership问题）</p>

<h2 id="section-1">分析问题</h2>

<p>都有哪些方案可以解决这个问题？</p>

<p>一种简单的想法是把url存储在一个哈希表中，每次去表里look up下判断是否存在。假如每个url占用40B，那么10亿条url将占用大概30多GB的内存！Can this be more space efficient ?</p>

<h2 id="section-2">解决问题</h2>

<p>我们可不可以不存url本身？这样子所需空间就会大大减少了。于是我们想到一个很经典的做法：bitmap（位图）。将集合S中的url哈希到bitmap上，给定一个url，只需要将它hash，得到它在bitmap的下标，检查该位置是否为1即可。</p>

<p>这样做空间是省了，可是也产生了一个问题：由于冲突（碰撞），不是集合S中的元素也可能被哈希到值为1的位置上，导致误报。</p>

<p>给定一个元素e，如果实际上$e\notin S$ 而被判为 $e\in S$，那么我们称e是false positive（伪正例。顺便说一句，false positive等的分析在machine learning的classification任务里评价model时非常重要）。</p>

<p>如何降低false positive的概率呢？Bloom Filter的想法是使用多个独立的哈希函数。</p>

<h3 id="standard-bloom-filter">Standard Bloom Filter</h3>

<p>在传统的Bloom Filter中，我们有：</p>

<p>集合S：其大小为m。也就是说，集合中有m个不同元素。</p>

<p>可用内存B：B被当成位数组bitmap来使用，大小为n。（有n个bit）。</p>

<p>哈希函数：有k个独立的、均匀分布的哈希函数。</p>

<p>Bloom Filter的做法是：初始时，所有比特位都初始化为0。对于集合中的每个元素，利用k个哈希函数，对它哈希得到k个位置，将bitmap中的对应的k个位置置为1。</p>

<p>给定一个元素e，为了判断它是否是集合中的元素，也利用该k个函数得到k个位置，检查该k个位置是否都为1，如果是，认为$e\in S$，否则认为$e\notin S$。</p>

<p>不难看出，如果$e\in S$，那么Bloom Filter肯定会正确判断出$e\in S$，但是它还是可能产生false positive。那么，如何分析false positive的概率呢？</p>

<p>false positive发生时，表示哈希该元素后得到的k个位置都为1。这个概率大概为：</p>

<p>$P\approx p_1^k$</p>

<p>其中$p_1$代表某位为1的概率，它等于：</p>

<p>$p_1 = 1 - p_0$</p>

<p>对于$p_0$，表示某个特定的比特位为0。什么时候该位才为0呢？也就是说m个元素各自经过k次哈希得到km个对象，没有一个对象定位到了该位置。某个对象定位到该位置的概率为$\frac{1}{n}$，因此我们可以得到：</p>

<p>$p_0 = (1 - \frac{1}{n})^{mk}$</p>

<p>分析$p_0$。在实际应用中，n一般很大，根据重要极限公式，我们有：</p>

<p>$p_0 = (1 - \frac{1}{n})^{mk} = (1-\frac{1}{n})^{-n{\frac{mk}{-n}}} \approx e^{-\frac{mk}{n}} $</p>

<p>代入到最上面的那个式子，我们不难得到：</p>

<p>$P \approx ({1 - e^{-\frac{mk}{n}}})^{k}$</p>

<p>当k为何值时，P取得最小，false positive possibility最低呢？</p>

<p>令 $f(k) = ({1 - e^{-\frac{mk}{n}}})^{k}$</p>

<p>$ln(f(k)) = kln({1 - e^{-\frac{mk}{n}}})$</p>

<p>$\frac{f\prime(k)}{f(k)} = ln({1 - e^{-\frac{mk}{n}}}) + k(\frac{1}{1 - e^{- \frac{mk}{n}}})(- e^{-\frac{mk}{n}})(\frac{-m}{n})$</p>

<p>$f\prime(k) = f(k)(ln({1 - e^{-\frac{mk}{n}}}) + k(\frac{1}{1 - e^{- \frac{mk}{n}}})(- e^{-\frac{mk}{n}})(\frac{-m}{n}))$</p>

<p>看起来够复杂了，然而别怕！！！</p>

<p>令$f\prime(k) = 0$ ， 我们有(注意到$f(k) &gt; 0$ 恒成立)：</p>

<p>$ln({1 - e^{-\frac{mk}{n}}}) + k(\frac{1}{1 - e^{- \frac{mk}{n}}})(- e^{- \frac{mk}{n}})(\frac{-m}{n}) = 0$</p>

<p>作代换，令$\lambda = e^{-\frac{mk}{n}}$ 则 $k = \frac{-nln\lambda}{m}$，代入上式，得到</p>

<p>$(1-\lambda)ln(1-\lambda) = \lambda ln\lambda$</p>

<p>因此$\lambda = \frac{1}{2}$ ， $k = \frac{n}{m}ln2$</p>

<p>也就是说，当n和m固定时，选择$k = \frac{n}{m}ln2$ 附近的一个整数，将使false positive possibility最小。</p>

<p>工程实现时，我们需要k个哈希函数或者哈希函数值。如何构造和获得k个独立的哈希函数呢？这篇<a href="https://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf">论文</a> 提出，只需要两个独立的哈希函数hf1和hf2即可，也就是通过如下方式获得k个哈希函数值：</p>

<p>hash value = hf1(key) + i*hf2(key)</p>

<p>其中i=0、1、2…k-1</p>

<h3 id="counting-bloom-filter">Counting Bloom Filter</h3>

<p>除了存在false positive这个问题之外，传统的Bloom Filter还有一个不足：无法支持删除操作（想想看，是不是这样的）。而Counting Bloom Filter(CBF)就是用来解决这个问题的。</p>

<p>在CBF中，维护的不是单纯的标示0或者1的比特位，而是计数器counter。对于集合中的每个元素，利用k个哈希函数，对它哈希得到k个位置，将对应的k个位置上的k个counter都加1。删除时，只需要把k个counter都减1即可。</p>

<p>那么，这个counter应该占用几位呢？分配太多，浪费空间；分配太少，容易溢出。通过下面的分析，我们可以知道，实际使用时，4位足矣。</p>

<p>考察（是考察，不是考查。这两个词有什么区别？）某个位置，该位置的计数器counter的值$\xi$</p>

<p>$P(\xi = c) \approx \binom{mk}{c} {(\frac{1}{n})}^{c}({1-\frac{1}{n}})^{mk-c} = B(km,\frac{1}{n})$</p>

<p>这个式子有点点复杂，然而回忆下概率论里的知识：若二项分布B(n,p)里n很大，p很小时，二项分布的极限近似分布是泊松分布$P(\lambda=k) = \frac{\lambda^k}{k!}{e}^{-\lambda}$，其中$\lambda=np$，因此：</p>

<p>$P(\xi = c) \approx \binom{mk}{c} {(\frac{1}{n})}^{c}({1-\frac{1}{n}})^{mk-c} \approx \frac{({\frac{km}{n}})^{c}}{c!}{e}^{-{\frac{km}{n}}}$</p>

<p>令$k = \frac{n}{m}ln2$，代入，我们得到</p>

<p>$P(\xi &gt;16) \approx \frac{(ln2)^{16}}{16!} * \frac{1}{2} &lt; \frac{1}{16!} = \frac{1}{20922789888000}$</p>

<p>也就是说，选择4位来存counter在实际情况中已经足矣，发生溢出的概率极小。</p>

<h2 id="section-3">本文小结</h2>

<p>总结下，Bloom Filter可以用在什么地方，或者说，在什么场景下，你应该想到这种技术：</p>

<p>1，回答是或者不是的问题。你需要判断一个元素是否属于某个集合，仅仅这样。你不应该要求更多。如果你想获得该元素对应的value或者还有其他payload，那么bloom filter不适合你，你需要哈希表。</p>

<p>2，允许false positive。也就是说，发生false positive不应该是致命的。比如说，搜索引擎的爬虫里，如果url不是set的元素，却被bloom filter过滤了，那么顶多就是不抓它而已，没啥特别大的损失。</p>

<p>3，空间敏感。作为一种概率数据结构，Bloom Filter不存储原始数据（比如说url），这也是它为什么space efficient的本质原因。</p>

<p>有了Standard Bloom Filter和Counting Bloom Filter，似乎可以满足绝大多数需求了，然而，这里面还是有问题。什么问题？请看下集。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction To Cuckoo Hashing]]></title>
    <link href="http://www.yebangyu.org/blog/2015/12/19/cuckoo-hashing/"/>
    <updated>2015-12-19T00:41:37+08:00</updated>
    <id>http://www.yebangyu.org/blog/2015/12/19/cuckoo-hashing</id>
    <content type="html"><![CDATA[<h2 id="motivation--intuition">Motivation &amp; Intuition</h2>

<p>为什么引入<strong>Cuckoo Hashing</strong>？</p>

<p>常见的<strong>hashing</strong>处理冲突方法一般包括两种：<strong>Separate Chaining</strong>和<strong>Open Addressing</strong>（<strong>Linear Probing</strong>）。<strong>Separate Chaining</strong>是将冲突的元素组织成一个链表（其实组织成一个二叉搜索树也是完全没问题的，甚至跳表也行），<strong>Open Addressing</strong>将冲突的元素还是放在哈希表<strong>slot</strong>中，使用线性探测等方法进行处理。</p>

<p>那么，这两种方法，都有啥优缺点呢？</p>

<!--more-->

<p><strong>Separate Chaining</strong> : 实现简单，但是对<strong>cache</strong>不友好，<strong>cache miss rate</strong>较高。</p>

<p><strong>Open Addressing</strong> : 实现相对复杂一点点，对<strong>cache</strong>很友好，但是对<strong>load factor</strong>要求苛刻：<strong>load factor</strong>稍高性能就急剧下降。</p>

<p>这两种方式下，查找某个元素的最坏时间都是<strong>O(n)</strong>。</p>

<p>你说，<strong>OK，OK</strong>，我知道，这些都是常识。那么，是否可以做到查找最坏是<strong>O(1)</strong>呢？</p>

<p>一种思路是元素只可能被安置到有限的常数(记为<strong>K</strong>)个位置，插入时，如果发生冲突，由于每个元素可以存放的位置有<strong>K</strong>个，因此可以对表部分元素进行重排，产生一个空缺的位置。</p>

<p><strong>Cuckoo Hashing</strong>就是这样的方式。当<strong>K=2</strong>时，<strong>Cuckoo Hashing</strong>在<strong>load factor</strong>为<strong>50%</strong>左右的情况下表现较佳。如果<strong>K=4</strong>，那么甚至可以在<strong>97%</strong>的<strong>load factor</strong>下良好工作。</p>

<h2 id="cuckoo-hashing">Cuckoo Hashing</h2>

<p>一般的<strong>Hashing</strong>只包括一个<strong>Hash Tables</strong>，但是<strong>Cuckoo Hashing</strong>由两张甚至多张表构成。每张表对应一个哈希函数。本文讨论两张哈希表（记为<strong>table1</strong>和<strong>table2</strong>）、两个哈希函数（记为<strong>hf1</strong>和<strong>hf2</strong>）这种常见情形。</p>

<h3 id="insert">Insert</h3>

<p>首先通过<strong>hf1</strong>计算出一个<strong>slot index</strong>，然后查看<strong>table1</strong>中该<strong>slot</strong>是否<strong>vacant</strong>，如果是，则插入；否则通过<strong>hf2</strong>计算出一个<strong>slot index</strong>，通过查看<strong>table2</strong>中该<strong>slot</strong>是否<strong>vacant</strong>，如果是，则插入，否则执行<strong>rearrange</strong>操作。</p>

<p><strong>rearrange</strong>操作的过程：随机选出一张表，将<strong>slot index</strong>对应的那个元素踢出(<strong>evict</strong>)，把我们待插入的元素插到那个位置。那被踢出来的元素呢？尝试插入到另外一张表对应的<strong>slot</strong>处，这时候可能又踢出一个元素，接下去就是递归的执行这个过程，直到所有元素都安置妥当。</p>

<p>举个例子吧，假如某个时刻，两个哈希表的内容如下：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/table1.jpg" alt="table1" /></p>

<p>假设我们待插入的元素为<strong>77</strong>。</p>

<p><strong>slot index1 = hf1(77) = 1</strong></p>

<p><strong>Table1</strong>中的<strong>index</strong>为<strong>1</strong>的<strong>slot</strong>已经被<strong>78</strong>占了。那么看<strong>Table2</strong>：</p>

<p><strong>slot index2 = hf2(77) = 3</strong></p>

<p><strong>Table2</strong>中的<strong>index</strong>为<strong>3</strong>的<strong>slot</strong>已经被<strong>33</strong>占了。因此执行<strong>rearrange</strong>。</p>

<p>执行<strong>rearrange</strong>动作，选择<strong>Table2</strong>，将<strong>slot index = 3</strong>的元素<strong>33</strong>踢出，插入<strong>77</strong>。然后被踢出的元素<strong>33</strong>，计算它在<strong>Table1</strong>中的<strong>index</strong>为<strong>slot index1 = hf2(33) = 2</strong>，因此将<strong>95</strong>踢出，插入<strong>33</strong>。被踢出的元素<strong>95</strong>在<strong>Table2</strong>中的<strong>slot index</strong>为<strong>2</strong>，该<strong>slot</strong>为<strong>vacant</strong>，没人使用，因此将<strong>95</strong>插入。完毕。现在的<strong>Tables</strong>中元素为：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/table2.jpg" alt="table2" /></p>

<p>值得注意的是，<strong>rearrange</strong>可能失败（表满了;或者发生“死循环”），此时需要进行<strong>rehash</strong>，因此代码里需要有一定的判断。当<strong>K=2</strong>时，只要<strong>load factor</strong>低于<strong>50%</strong>，需要<strong>rehash</strong>的概率很小很小。</p>

<p>在某些假设下，插入操作的摊还期望复杂度为常数时间。</p>

<h3 id="find">Find</h3>

<p>要检查的<strong>slot</strong>一共两个，<strong>index</strong>分别为<strong>hf1(key)</strong>和<strong>hf2(key)</strong>，因此只要查看一下<strong>Table1</strong>中的<strong>hf1(key)</strong>以及<strong>Table2</strong>中的<strong>hf2(key)</strong>这两个<strong>slot</strong>即可。时间复杂度为<strong>O(1)</strong>。</p>

<h3 id="del">Del</h3>

<p>同<strong>Find</strong>，要检查的<strong>slot</strong>也就两个，复杂度为<strong>O(1)</strong>。</p>

<h2 id="section">实现</h2>

<p>简单实现了一个，有需要的可以参考<a href="https://github.com/yebangyu/Yedis/blob/master/src/ds/CuckooHashMap.h">这里</a></p>

<h2 id="section-1">其他</h2>

<p>1，我们注意到，<strong>Cuckoo Hashing</strong>的精髓是使用两个不同的哈希函数，而不是两张表。两张表的存在，仅仅是为了分析上的方便。</p>

<p>当需要<strong>rehash</strong>而<strong>load factor</strong>又没达到<strong>100%</strong>时，我们其实不需要扩容哈希表，只需要更换哈希函数。</p>

<p>2，为嘛叫做<strong>Cuckoo Hashing</strong>？<strong>Cuckoo</strong>，即杜鹃鸟（布谷鸟），这种鸟有一种尿性：孵卵寄生。把蛋产到别的鸟窝里，让别人帮它孵化。这还不算，还要把人家寄主的一些卵给移走（不然容易引起怀疑嘛，毕竟鸟窝里突然多出几枚蛋。至于移走多少，就得看杜鹃鸟数学合不合格了）！等卵孵化完成，幼雏会将鸟窝里寄主的卵和其他幼雏推出鸟窝。真是牛逼闪闪了。</p>

<h2 id="section-2">参考文献</h2>

<p>http://resources.mpi-inf.mpg.de/departments/d1/teaching/ws14/AlgoDat/materials/cuckoo.pdf</p>

<p><strong>Cuckoo Hashing</strong>原始论文</p>

<p>https://www.eecs.harvard.edu/~michaelm/postscripts/esa2009.pdf</p>

<p>这篇文章介绍了一些关于<strong>Cuckoo Hashing</strong>的<strong>Open Questions</strong></p>

<p>http://web.stanford.edu/class/cs166/lectures/13/Slides13.pdf</p>

<p>这个<strong>slides</strong>偏重对<strong>Cuckoo Hashing</strong>理论上的分析，注意其中对于插入操作的处理和本文介绍的不同。</p>

<p>http://excess-project.eu/publications/published/CuckooHashing_ICDCS.pdf</p>

<p>碉堡了，<strong>Lock Free Cuckoo Hashing</strong>。</p>
]]></content>
  </entry>
  
</feed>
